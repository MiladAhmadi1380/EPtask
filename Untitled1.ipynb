{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2222f50d-9693-4e2f-8176-1072e0bd0a34",
      "metadata": {
        "id": "2222f50d-9693-4e2f-8176-1072e0bd0a34",
        "outputId": "05995970-6625-471c-b584-73694353b794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D:\\app\\Anaconda\\python.exe\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "322c6568-ff4a-4a16-8ace-5dc245f0b02f",
      "metadata": {
        "id": "322c6568-ff4a-4a16-8ace-5dc245f0b02f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from typing import Tuple\n",
        "from collections import deque\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import random\n",
        "import os\n",
        "# stable-baselines3\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97c9e0c-fe04-4082-b0fc-4bc41e25c496",
      "metadata": {
        "id": "d97c9e0c-fe04-4082-b0fc-4bc41e25c496"
      },
      "outputs": [],
      "source": [
        "# --- Environment Parameters ---\n",
        "NUM_VEHICLES_TRAIN = 30  # Number of vehicles for training\n",
        "NUM_EDGE_SERVERS = 8\n",
        "MAX_TASKS_PER_VEHICLE = 10\n",
        "CPU_CYCLES_TASK_MCYCLES = (2, 20)  # CPU cycles in million cycles (MCycles)\n",
        "DATA_SIZE_TASK_Mbits = (2, 20)    # Data size in Mbits\n",
        "VEHICLE_COMP_POWER_MCYCLES_PER_SEC = 1  #  1 Mcycles/sec\n",
        "EDGE_COMP_POWER_MCYCLES_PER_SEC = 2    # 2 Mcycles/sec\n",
        "CLOUD_COMP_POWER_MCYCLES_PER_SEC = 10  # 10 Mcycles/sec (Assumed very high)\n",
        "\n",
        "# Communication Parameters\n",
        "VEHICLE_BANDWIDTH_MHZ = 100 # MHz\n",
        "EDGE_BANDWIDTH_MHZ = 100    # MHz\n",
        "CLOUD_BANDWIDTH_MHZ = 1000  # MHz (Assumed high)\n",
        "VEHICLE_TRANSMIT_POWER_DBM = 1 # dBm\n",
        "VEHICLE_EXECUTION_POWER_DBM = 3 # dBm (for local execution)\n",
        "EDGE_TX_POWER_DBM = 20   # dBm (فرض معقول برای Edge)\n",
        "CLOUD_TX_POWER_DBM = 30  # dBm (فرض معقول برای Cloud)\n",
        "NOISE_POWER_DBM_PER_HZ = -174 # dBm/Hz\n",
        "POWER_CONSUMPTION_COEFFICIENT_XI = 1e-11\n",
        "POWER_CONSUMPTION_COEFFICIENT_GAMMA = 2\n",
        "RSSI_DBM = -90 # Received Signal Strength Indicator\n",
        "TX_ANTENNA_GAIN_DBI = 20 # Transmit antenna gain\n",
        "RX_ANTENNA_GAIN_DBI = -8 # Receive antenna gain (as per paper, can be negative)\n",
        "SIGNAL_ATTENUATION_DB = 7 # Signal attenuation caused by obstacles\n",
        "WORKING_FREQUENCY_MHZ = 5000 # MHz\n",
        "SPEED_VEHICLES_MPS = 25  # m/s (تقریباً 90km/h)\n",
        "\n",
        "# Mobility Model (Simplified for highway)\n",
        "HIGHWAY_LENGTH_M = 10000 # 10 km highway\n",
        "VEHICLE_COVERAGE_RANGE_M = 500 # Vehicles can communicate within 500m\n",
        "EDGE_SERVER_COVERAGE_RANGE_M = 1000 # Edge servers cover 1000m radius\n",
        "EDGE_SERVER_LOCATIONS = [(i * HIGHWAY_LENGTH_M / (NUM_EDGE_SERVERS + 1), 0) for i in range(1, NUM_EDGE_SERVERS + 1)] # Evenly distributed\n",
        "\n",
        "# Problem Formulation Weights\n",
        "WEIGHT_COMPLETION_TIME = 0.5\n",
        "WEIGHT_ENERGY_CONSUMPTION = 0.5\n",
        "\n",
        "# Constraints\n",
        "MAX_TASK_DEADLINE_S = 2 # s\n",
        "MAX_ENERGY_BUDGET_J = 10000 # Joules\n",
        "\n",
        "# --- PPO Agent Parameters ---\n",
        "LEARNING_RATE = 0.0003\n",
        "N_STEPS = 2048 # Number of steps to run for each environment per update\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCHS = 10 # Number of epoch when optimizing the surrogate loss\n",
        "GAMMA = 0.99 # Discount factor\n",
        "GAE_LAMBDA = 0.95 # Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
        "CLIP_RANGE = 0.2 # Clipping parameter, for PPO\n",
        "ENT_COEF = 0.01 # Entropy coefficient for the loss calculation\n",
        "VF_COEF = 0.5 # Value function coefficient for the loss calculation\n",
        "\n",
        "TOTAL_TIMESTEPS = 500000 # Total number of samples to train the agent\n",
        "\n",
        "# --- Training Parameters ---\n",
        "LOG_INTERVAL = 10 # Log every N episodes\n",
        "SAVE_PATH = \"results/trained_model_ppo.zip\"\n",
        "LOG_DIR = \"results/\"\n",
        "LOG_FILE = \"logs.csv\"\n",
        "\n",
        "# --- Testing Parameters ---\n",
        "NUM_TEST_EPISODES = 100\n",
        "TEST_VEHICLE_COUNTS = [10, 20, 30, 40, 50]\n",
        "TEST_METHODS = [\"MEPPO\", \"DDPG\", \"SAC\", \"Local-only\", \"Offloading-only\", \"Random\"] # Add \"PPO-no-priority\", \"PPO-no-dynamic-power\" for ablation studies if needed\n",
        "\n",
        "# --- Plotting Parameters ---\n",
        "PLOT_TITLE_FONTSIZE = 14\n",
        "PLOT_LABEL_FONTSIZE = 12\n",
        "PLOT_LEGEND_FONTSIZE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df6b6a94-b817-4c85-9c23-17e5f70fb35e",
      "metadata": {
        "id": "df6b6a94-b817-4c85-9c23-17e5f70fb35e"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# تبدیل‌ها\n",
        "# ----------------------------\n",
        "def dbm_to_mw(dbm: float) -> float:\n",
        "    \"\"\"milliwatts from dBm\"\"\"\n",
        "    return 10.0 ** (dbm / 10.0)\n",
        "\n",
        "def mw_to_dbm(mw: float) -> float:\n",
        "    \"\"\"dBm from milliwatts\"\"\"\n",
        "    return 10.0 * math.log10(mw)\n",
        "\n",
        "def dbm_to_watt(dbm: float) -> float:\n",
        "    \"\"\"Watt from dBm\"\"\"\n",
        "    return dbm_to_mw(dbm) * 1e-3\n",
        "\n",
        "def watt_to_dbm(watt: float) -> float:\n",
        "    \"\"\"dBm from Watt\"\"\"\n",
        "    mw = watt * 1e3\n",
        "    return mw_to_dbm(mw)\n",
        "\n",
        "# ----------------------------\n",
        "# SNR و نرخ (با RSSI ثابت)\n",
        "# ----------------------------\n",
        "def calculate_snr_linear(received_power_watt: float, bandwidth_mhz: float,\n",
        "                         interference_watt: float = 0.0,\n",
        "                         noise_dbm_per_hz: float = NOISE_POWER_DBM_PER_HZ) -> float:\n",
        "    \"\"\"\n",
        "    محاسبه SNR (خطی) = received_power / (interference + noise_total)\n",
        "    bandwidth_mhz: پهنای باند مورد استفاده (MHz)\n",
        "    noise_dbm_per_hz: نویز سفید (dBm/Hz) معمولاً -174 dBm/Hz\n",
        "    \"\"\"\n",
        "    bandwidth_hz = bandwidth_mhz * 1e6\n",
        "    # تبدیل dBm/Hz -> W/Hz\n",
        "    noise_w_per_hz = 10 ** ((noise_dbm_per_hz - 30.0) / 10.0)\n",
        "    noise_total_w = noise_w_per_hz * bandwidth_hz\n",
        "    denom = interference_watt + noise_total_w\n",
        "    if denom <= 0:\n",
        "        return 0.0\n",
        "    return received_power_watt / denom\n",
        "\n",
        "def calculate_data_rate_bps(bandwidth_mhz: float, snr_linear: float) -> float:\n",
        "    \"\"\"\n",
        "    نرخ بر حسب bps با استفاده از قضیهٔ شانون:\n",
        "    R = B * log2(1 + SNR)\n",
        "    \"\"\"\n",
        "    if snr_linear <= 0:\n",
        "        return 0.0\n",
        "    bandwidth_hz = bandwidth_mhz * 1e6\n",
        "    return bandwidth_hz * math.log2(1.0 + snr_linear)\n",
        "\n",
        "# ----------------------------\n",
        "# wrapper ساده: همیشه از RSSI ثابت استفاده می‌کند\n",
        "# ----------------------------\n",
        "def estimate_link_rate_and_snr(tx_power_dbm: float, distance_m: float, bandwidth_mhz: float,\n",
        "                              tx_gain_dbi: float = None, rx_gain_dbi: float = None,\n",
        "                              signal_attenuation_db: float = None, interference_watt: float = 0.0) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    نسخهٔ ساده‌شده برای آموزش/تست:\n",
        "    - این تابع مقدار RSSI را از ثابت RSSI_DBM در config می‌گیرد (نسبت به فاصله یا توان توجهی نمی‌کند).\n",
        "    - آرگومان‌های tx_power_dbm و distance_m پذیرفته می‌شوند تا با امضای توابع قبلی سازگار باشد،\n",
        "      ولی در محاسبات استفاده نمی‌شوند (برای سادگی و ثبات).\n",
        "    - خروجی: (rate_bps, snr_linear)\n",
        "    \"\"\"\n",
        "    # دریافت توان دریافت‌شده از RSSI ثابت (dBm -> Watt)\n",
        "    recv_watt = dbm_to_watt(RSSI_DBM)\n",
        "\n",
        "    # محاسبه SNR خطی با توجه به پهنای باند و تداخل (در صورت وجود)\n",
        "    snr_lin = calculate_snr_linear(recv_watt, bandwidth_mhz, interference_watt=interference_watt)\n",
        "\n",
        "    # محاسبه نرخ بر حسب bps\n",
        "    rate_bps = calculate_data_rate_bps(bandwidth_mhz, snr_lin)\n",
        "\n",
        "    return rate_bps, snr_lin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9630263-f7d3-4758-b9a9-a86eb1291e62",
      "metadata": {
        "id": "d9630263-f7d3-4758-b9a9-a86eb1291e62",
        "outputId": "5c5d1485-0f8a-4130-c242-11777fa056e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SNR (linear): 2.512e+00\n",
            "Data rate: 181.225 Mbps\n"
          ]
        }
      ],
      "source": [
        "rate_bps, snr = estimate_link_rate_and_snr(\n",
        "        tx_power_dbm=VEHICLE_TRANSMIT_POWER_DBM,\n",
        "        distance_m=200.0,\n",
        "        bandwidth_mhz=VEHICLE_BANDWIDTH_MHZ\n",
        "    )\n",
        "print(f\"SNR (linear): {snr:.3e}\")\n",
        "print(f\"Data rate: {rate_bps / 1e6:.3f} Mbps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c663ad-eb49-4976-ac7a-f209af85b00f",
      "metadata": {
        "id": "e3c663ad-eb49-4976-ac7a-f209af85b00f"
      },
      "outputs": [],
      "source": [
        "class Task:\n",
        "    def __init__(self, task_id: int, cpu_cycles_mcycles: float, data_size_mb: float,\n",
        "                 deadline_s: float = MAX_TASK_DEADLINE_S, origin_id: int = None):\n",
        "        self.task_id = task_id\n",
        "        self.origin_id = origin_id\n",
        "\n",
        "        # واحدها: cpu Mcycles, data MB\n",
        "        self.cpu_cycles_mcycles = float(cpu_cycles_mcycles)\n",
        "        self.data_size_mb = float(data_size_mb)\n",
        "\n",
        "        self.deadline_s = float(deadline_s)\n",
        "        self.priority = 1\n",
        "        self.offloading_decision = None   # 0=edge,1=vehicle,2=local,3=cloud\n",
        "        self.assigned_entity = None\n",
        "\n",
        "        self.remaining_cpu_mcycles = float(cpu_cycles_mcycles)\n",
        "        self.remaining_data_mb = float(data_size_mb)\n",
        "\n",
        "        self.start_time_s = None\n",
        "        self.finish_time_s = None\n",
        "\n",
        "        # انرژی (جامع و با واحد ژول)\n",
        "        self.transmission_energy_j = 0.0\n",
        "        self.computation_energy_j = 0.0\n",
        "\n",
        "        self.done = False\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Task(id={self.task_id}, origin={self.origin_id}, cpu_Mc={self.cpu_cycles_mcycles:.2f}, \"\n",
        "                f\"data_MB={self.data_size_mb:.2f}, rem_cpu={self.remaining_cpu_mcycles:.2f}, \"\n",
        "                f\"rem_data={self.remaining_data_mb:.2f}, prio={self.priority}, done={self.done})\")\n",
        "\n",
        "    def mark_started(self, now_s):\n",
        "        if self.start_time_s is None:\n",
        "            self.start_time_s = now_s\n",
        "\n",
        "    def mark_finished(self, now_s):\n",
        "        self.finish_time_s = now_s\n",
        "        self.done = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e18b373-0bff-401b-8429-c570dad28ea1",
      "metadata": {
        "id": "1e18b373-0bff-401b-8429-c570dad28ea1"
      },
      "outputs": [],
      "source": [
        "class BaseComputeEntity:\n",
        "    def __init__(self, entity_id, location=(0.0, 0.0), cpu_freq_mhz: float = 1.0):\n",
        "        self.entity_id = entity_id\n",
        "        self.location = np.array(location, dtype=float)\n",
        "        self.cpu_freq_mhz = float(cpu_freq_mhz)\n",
        "\n",
        "        self.task_queue = deque()\n",
        "        self.current_transmissions = {}\n",
        "        self.energy_consumed_j = 0.0\n",
        "        self.last_update_time_s = 0.0\n",
        "        self.processed_tasks_history = []\n",
        "\n",
        "    def add_task_to_queue(self, task: Task, priority: int = 1):\n",
        "        task.priority = priority\n",
        "        self.task_queue.append((task, priority))\n",
        "        self.task_queue = deque(sorted(list(self.task_queue), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    def reset(self):\n",
        "        self.task_queue.clear()\n",
        "        self.current_transmissions.clear()\n",
        "        self.energy_consumed_j = 0.0\n",
        "        self.processed_tasks_history.clear()\n",
        "\n",
        "    def get_current_workload_mcycles(self):\n",
        "        return sum(t.remaining_cpu_mcycles for t, _ in self.task_queue)\n",
        "\n",
        "    def process_step(self, dt_s: float, now_s: float):\n",
        "        processed_tasks = []\n",
        "        remaining_time = dt_s\n",
        "        self.last_update_time_s = now_s\n",
        "\n",
        "        while self.task_queue and remaining_time > 1e-12:\n",
        "            task, priority = self.task_queue[0]\n",
        "            cycles_can_do = self.cpu_freq_mhz * remaining_time * 1e6  # Mcycles to cycles? نه, cpu_freq_mhz Mcycle/sec? units fix\n",
        "\n",
        "            if task.remaining_cpu_mcycles <= cycles_can_do / 1e6:  # adjust\n",
        "                time_used = task.remaining_cpu_mcycles / self.cpu_freq_mhz\n",
        "                f_hz = self.cpu_freq_mhz * 1e6  # MHz to Hz\n",
        "                C_cycles = task.remaining_cpu_mcycles * 1e6  # Mcycles to cycles\n",
        "                energy_j = POWER_CONSUMPTION_COEFFICIENT_XI * (f_hz ** POWER_CONSUMPTION_COEFFICIENT_GAMMA) * C_cycles\n",
        "                task.computation_energy_j += energy_j\n",
        "                self.energy_consumed_j += energy_j\n",
        "                task.remaining_cpu_mcycles = 0.0\n",
        "                task.mark_finished(now_s + time_used)\n",
        "                processed_tasks.append(task)\n",
        "                self.task_queue.popleft()\n",
        "                remaining_time -= time_used\n",
        "            else:\n",
        "                C_done = cycles_can_do\n",
        "                energy_j = POWER_CONSUMPTION_COEFFICIENT_XI * (f_hz ** POWER_CONSUMPTION_COEFFICIENT_GAMMA) * C_done\n",
        "                task.remaining_cpu_mcycles -= C_done / 1e6\n",
        "                task.computation_energy_j += energy_j\n",
        "                self.energy_consumed_j += energy_j\n",
        "                remaining_time = 0.0\n",
        "\n",
        "        return processed_tasks\n",
        "                else:\n",
        "                # بخشی از کار\n",
        "                f_hz = self.cpu_freq_mhz * 1e6\n",
        "                cycles_done = cycles_can_do * 1e6\n",
        "                energy_j = POWER_CONSUMPTION_COEFFICIENT_XI * (self.cpu_freq_mhz ** POWER_CONSUMPTION_COEFFICIENT_GAMMA) * task.remaining_cpu_mcycles\n",
        "\n",
        "                task.remaining_cpu_mcycles -= cycles_can_do\n",
        "                task.computation_energy_j += energy_j\n",
        "                self.energy_consumed_j += energy_j\n",
        "                remaining_time = 0.0\n",
        "\n",
        "        return processed_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a526f5a3-d6f3-4621-8189-513fc9d5279b",
      "metadata": {
        "id": "a526f5a3-d6f3-4621-8189-513fc9d5279b"
      },
      "outputs": [],
      "source": [
        "class Vehicle(BaseComputeEntity):\n",
        "    def __init__(self, entity_id, location=(0.0,0.0), cpu_freq_mhz: float = VEHICLE_COMP_POWER_MCYCLES_PER_SEC,\n",
        "                 bandwidth_mhz: float = VEHICLE_BANDWIDTH_MHZ, tx_power_dbm: float = VEHICLE_TRANSMIT_POWER_DBM,\n",
        "                 speed_mps: float = SPEED_VEHICLES_MPS):\n",
        "        super().__init__(entity_id, location, cpu_freq_mhz)\n",
        "        self.bandwidth_mhz = float(bandwidth_mhz)\n",
        "        self.tx_power_dbm = float(tx_power_dbm)\n",
        "        self.tx_power_watt = dbm_to_watt(self.tx_power_dbm)\n",
        "        self.speed_mps = float(speed_mps)\n",
        "        self.outgoing_transmissions = {}\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Vehicle(id={self.entity_id}, loc={self.location.tolist()}, cpu={self.cpu_freq_mhz}MHz)\"\n",
        "\n",
        "    def move(self, dt: float):\n",
        "        self.location[0] = (self.location[0] + self.speed_mps * dt) % HIGHWAY_LENGTH_M\n",
        "\n",
        "    def start_transmission(self, task: Task, dest_entity: BaseComputeEntity, allocated_bw_mhz: float = None, tx_power_dbm: float = None):\n",
        "        if allocated_bw_mhz is None:\n",
        "            allocated_bw_mhz = self.bandwidth_mhz\n",
        "        if tx_power_dbm is None:\n",
        "            tx_power_dbm = self.tx_power_dbm\n",
        "\n",
        "        tx_info = {\n",
        "            'task': task,\n",
        "            'dest': dest_entity,\n",
        "            'allocated_bw_mhz': float(allocated_bw_mhz),\n",
        "            'tx_power_dbm': float(tx_power_dbm),\n",
        "            'progress_mb': 0.0,\n",
        "            'started': True\n",
        "        }\n",
        "        self.outgoing_transmissions[task.task_id] = tx_info\n",
        "        task.offloading_decision = 1 if isinstance(dest_entity, Vehicle) else (0 if dest_entity.__class__.__name__ == 'EdgeServer' else 3)\n",
        "        task.assigned_entity = dest_entity.entity_id\n",
        "\n",
        "    def progress_transmissions(self, dt: float, interference_watt: float = 0.0):\n",
        "        completed_transfers = []\n",
        "        to_remove = []\n",
        "        for tid, info in list(self.outgoing_transmissions.items()):\n",
        "            task = info['task']\n",
        "            dest = info['dest']\n",
        "            bw = info['allocated_bw_mhz']\n",
        "            tx_dbm = info['tx_power_dbm']\n",
        "\n",
        "            distance_m = np.linalg.norm(self.location - dest.location)\n",
        "            rate_bps, snr_lin = estimate_link_rate_and_snr(tx_dbm, distance_m, bw)\n",
        "            rate_mbps = rate_bps / 1e6\n",
        "\n",
        "            # **مهم**: rate_mbps (Mb/s) -> MB/s تقسیم بر 8\n",
        "            data_sent_mb = (rate_mbps * dt) / 8.0\n",
        "\n",
        "            info['progress_mb'] += data_sent_mb\n",
        "            task.remaining_data_mb = max(0.0, task.remaining_data_mb - data_sent_mb)\n",
        "\n",
        "            tx_power_watt = dbm_to_watt(tx_dbm)\n",
        "            energy_j = tx_power_watt * dt\n",
        "            self.energy_consumed_j += energy_j\n",
        "            task.transmission_energy_j += energy_j\n",
        "\n",
        "            if task.remaining_data_mb <= 1e-12:\n",
        "                completed_transfers.append((task, dest))\n",
        "                to_remove.append(tid)\n",
        "\n",
        "        for tid in to_remove:\n",
        "            del self.outgoing_transmissions[tid]\n",
        "\n",
        "        for task, dest in completed_transfers:\n",
        "            dest.add_task_to_queue(task, priority=task.priority)\n",
        "\n",
        "        return completed_transfers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa95f51b-3ac6-4a29-9db8-92fee1eb9165",
      "metadata": {
        "id": "aa95f51b-3ac6-4a29-9db8-92fee1eb9165"
      },
      "outputs": [],
      "source": [
        "class EdgeServer(BaseComputeEntity):\n",
        "    def __init__(self, entity_id, location=(0.0, 0.0), cpu_freq_mhz: float = EDGE_COMP_POWER_MCYCLES_PER_SEC,\n",
        "                 bandwidth_mhz: float = EDGE_BANDWIDTH_MHZ, tx_power_dbm: float = EDGE_TX_POWER_DBM):\n",
        "        super().__init__(entity_id, location, cpu_freq_mhz)\n",
        "        self.bandwidth_mhz = float(bandwidth_mhz)\n",
        "        self.tx_power_dbm = float(tx_power_dbm)\n",
        "        self.tx_power_watt = dbm_to_watt(self.tx_power_dbm)\n",
        "        self.connected_vehicles = set()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"EdgeServer(id={self.entity_id}, loc={self.location.tolist()}, cpu={self.cpu_freq_mhz}MHz)\"\n",
        "\n",
        "\n",
        "class CloudServer(BaseComputeEntity):\n",
        "    def __init__(self, entity_id=\"cloud_0\", location=(HIGHWAY_LENGTH_M/2, 5000.0), cpu_freq_mhz: float = CLOUD_COMP_POWER_MCYCLES_PER_SEC,\n",
        "                 bandwidth_mhz: float = CLOUD_BANDWIDTH_MHZ, tx_power_dbm: float = CLOUD_TX_POWER_DBM):\n",
        "        super().__init__(entity_id, location, cpu_freq_mhz)\n",
        "        self.bandwidth_mhz = float(bandwidth_mhz)\n",
        "        self.tx_power_dbm = float(tx_power_dbm)\n",
        "        self.tx_power_watt = dbm_to_watt(self.tx_power_dbm)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"CloudServer(id={self.entity_id}, loc={self.location.tolist()}, cpu={self.cpu_freq_mhz}MHz)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "168b60ab-86af-4444-ab23-935e204c1d05",
      "metadata": {
        "id": "168b60ab-86af-4444-ab23-935e204c1d05",
        "outputId": "a579d983-9cbb-435b-90ca-f0c3c1d5220c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Simple Entity Test ===\n",
            "Initial Task: Task(id=1, origin=1, cpu_Mc=5.00, data_MB=2.00, rem_cpu=5.00, rem_data=2.00, prio=1, done=False)\n",
            "Started transmission from Vehicle -> Edge\n",
            "\n",
            "--- Step 0 ---\n",
            "Vehicle position: [25.  0.]\n",
            "Progressed transmissions. Completed: [(Task(id=1, origin=1, cpu_Mc=5.00, data_MB=2.00, rem_cpu=5.00, rem_data=0.00, prio=1, done=False), EdgeServer(id=0, loc=[200.0, 0.0], cpu=2.0MHz))]\n",
            "Remaining data (MB): 0.0\n",
            "Vehicle energy consumed (J): 0.0012589254117941673\n",
            "Edge processed tasks: []\n",
            "Edge energy consumed (J): 1.9999999999999998e-10\n",
            "\n",
            "--- Step 1 ---\n",
            "Vehicle position: [50.  0.]\n",
            "Progressed transmissions. Completed: []\n",
            "Remaining data (MB): 0.0\n",
            "Vehicle energy consumed (J): 0.0012589254117941673\n",
            "Edge processed tasks: []\n",
            "Edge energy consumed (J): 3.2e-10\n",
            "\n",
            "--- Step 2 ---\n",
            "Vehicle position: [75.  0.]\n",
            "Progressed transmissions. Completed: []\n",
            "Remaining data (MB): 0.0\n",
            "Vehicle energy consumed (J): 0.0012589254117941673\n",
            "Edge processed tasks: [Task(id=1, origin=1, cpu_Mc=5.00, data_MB=2.00, rem_cpu=0.00, rem_data=0.00, prio=1, done=True)]\n",
            "Edge energy consumed (J): 3.6e-10\n",
            "✅ Task finished at step 2\n",
            "\n",
            "Test finished.\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Simple Entity Test ===\")\n",
        "\n",
        "# ساخت موجودیت‌ها\n",
        "v = Vehicle(entity_id=1, location=(0.0, 0.0))\n",
        "es = EdgeServer(entity_id=0, location=(200.0, 0.0))  # 200 متر فاصله\n",
        "cloud = CloudServer()\n",
        "\n",
        "# ساخت یک تسک\n",
        "t = Task(task_id=1, cpu_cycles_mcycles=5.0, data_size_mb=2.0, origin_id=v.entity_id)\n",
        "print(\"Initial Task:\", t)\n",
        "\n",
        "# شروع ارسال\n",
        "v.start_transmission(t, es, allocated_bw_mhz=10.0, tx_power_dbm=v.tx_power_dbm)\n",
        "print(\"Started transmission from Vehicle -> Edge\")\n",
        "\n",
        "# شبیه‌سازی گام‌های زمانی\n",
        "for step in range(5):\n",
        "    print(f\"\\n--- Step {step} ---\")\n",
        "    v.move(dt=1.0)\n",
        "    completed = v.progress_transmissions(dt=1.0)\n",
        "    print(\"Vehicle position:\", v.location)\n",
        "    print(\"Progressed transmissions. Completed:\", completed)\n",
        "    print(\"Remaining data (MB):\", t.remaining_data_mb)\n",
        "    print(\"Vehicle energy consumed (J):\", v.energy_consumed_j)\n",
        "\n",
        "    completed_proc = es.process_step(dt_s=1.0, now_s=step)\n",
        "    print(\"Edge processed tasks:\", completed_proc)\n",
        "    print(\"Edge energy consumed (J):\", es.energy_consumed_j)\n",
        "\n",
        "    if t.done:\n",
        "        print(\"✅ Task finished at step\", step)\n",
        "        break\n",
        "\n",
        "print(\"\\nTest finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c746b977-0443-4f5e-b4d5-e99cf17f1d94",
      "metadata": {
        "id": "c746b977-0443-4f5e-b4d5-e99cf17f1d94"
      },
      "outputs": [],
      "source": [
        "# fallback / alias برای اسم‌های مختلف کانفیگ (این رو اگر قبلاً نداری اضافه کن)\n",
        "DT = globals().get(\"DT\", 1.0)\n",
        "CPU_CYCLES_TASK_RANGE_MCY = globals().get(\"CPU_CYCLES_TASK_MCYCLES\", (2, 20))\n",
        "_cfg_data_mbits = globals().get(\"DATA_SIZE_TASK_Mbits\", None)\n",
        "if _cfg_data_mbits is not None:\n",
        "    DATA_SIZE_TASK_RANGE_MB = (_cfg_data_mbits[0] / 8.0, _cfg_data_mbits[1] / 8.0)\n",
        "else:\n",
        "    DATA_SIZE_TASK_RANGE_MB = globals().get(\"DATA_SIZE_TASK_RANGE_MB\", (0.25, 2.5))  # Mbit to MB adjusted\n",
        "VEHICLE_CPU_FREQ_MHZ = globals().get(\"VEHICLE_COMP_POWER_MCYCLES_PER_SEC\", 1.0)\n",
        "EDGE_CPU_FREQ_MHZ = globals().get(\"EDGE_COMP_POWER_MCYCLES_PER_SEC\", 2.0)\n",
        "CLOUD_CPU_FREQ_MHZ = globals().get(\"CLOUD_COMP_POWER_MCYCLES_PER_SEC\", 10.0)\n",
        "VEHICLE_BANDWIDTH_MHZ = globals().get(\"VEHICLE_BANDWIDTH_MHZ\", 100.0)\n",
        "EDGE_BANDWIDTH_MHZ = globals().get(\"EDGE_BANDWIDTH_MHZ\", 100.0)\n",
        "CLOUD_BANDWIDTH_MHZ = globals().get(\"CLOUD_BANDWIDTH_MHZ\", 1000.0)\n",
        "VEHICLE_TX_POWER_DBM = globals().get(\"VEHICLE_TRANSMIT_POWER_DBM\", 1.0)\n",
        "EDGE_TX_POWER_DBM = globals().get(\"EDGE_TX_POWER_DBM\", 20.0)\n",
        "CLOUD_TX_POWER_DBM = globals().get(\"CLOUD_TX_POWER_DBM\", 30.0)\n",
        "HIGHWAY_LENGTH_M = globals().get(\"HIGHWAY_LENGTH_M\", 10000.0)\n",
        "VEHICLE_COVERAGE_RANGE_M = globals().get(\"VEHICLE_COVERAGE_RANGE_M\", 500.0)\n",
        "EDGE_SERVER_LOCATIONS = globals().get(\"EDGE_SERVER_LOCATIONS\", [(i * HIGHWAY_LENGTH_M / (globals().get(\"NUM_EDGE_SERVERS\", 8) + 1), 0) for i in range(1, globals().get(\"NUM_EDGE_SERVERS\", 8)+1)])\n",
        "MAX_TASKS_PER_VEHICLE = globals().get(\"MAX_TASKS_PER_VEHICLE\", 10)\n",
        "RANDOM_SEED = globals().get(\"RANDOM_SEED\", 0)\n",
        "WEIGHT_DELAY = globals().get(\"WEIGHT_COMPLETION_TIME\", 0.5)\n",
        "WEIGHT_ENERGY = globals().get(\"WEIGHT_ENERGY_CONSUMPTION\", 0.5)\n",
        "SPEED_VEHICLES_MPS = globals().get(\"SPEED_VEHICLES_MPS\", 25.0)\n",
        "MAX_VEHICLES = 50  # جدید: max برای pad\n",
        "\n",
        "class VECEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, num_vehicles: int = 10, max_tasks_per_vehicle: int = MAX_TASKS_PER_VEHICLE, episode_duration_s: int = 200):\n",
        "        super().__init__()\n",
        "        self.num_vehicles = min(num_vehicles, MAX_VEHICLES)  # محدود به max\n",
        "        self.max_tasks_per_vehicle = max_tasks_per_vehicle\n",
        "        self.episode_duration_s = episode_duration_s\n",
        "        self.current_time_s = 0.0\n",
        "        self.vehicles = {}\n",
        "        self.edges = {}\n",
        "        self.cloud = None\n",
        "        self.all_tasks = {}\n",
        "        self.task_counter = 0\n",
        "        self._init_entities()\n",
        "        obs_dim = 3 * MAX_VEHICLES + 3  # ثابت برای max\n",
        "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(obs_dim,), dtype=np.float32)\n",
        "        self.action_space = spaces.MultiDiscrete([4] * MAX_VEHICLES)  # ثابت برای max\n",
        "        self.seed(RANDOM_SEED)\n",
        "\n",
        "    def _init_entities(self):\n",
        "        for i, loc in enumerate(EDGE_SERVER_LOCATIONS):\n",
        "            es = EdgeServer(entity_id=f\"es_{i}\", location=loc, cpu_freq_mhz=EDGE_CPU_FREQ_MHZ, bandwidth_mhz=EDGE_BANDWIDTH_MHZ, tx_power_dbm=EDGE_TX_POWER_DBM)\n",
        "            self.edges[i] = es\n",
        "        self.cloud = CloudServer(entity_id=\"cloud_0\", location=(HIGHWAY_LENGTH_M/2, 5000.0), cpu_freq_mhz=CLOUD_CPU_FREQ_MHZ, bandwidth_mhz=CLOUD_BANDWIDTH_MHZ, tx_power_dbm=CLOUD_TX_POWER_DBM)\n",
        "        for i in range(self.num_vehicles):\n",
        "            x = float(np.random.uniform(0, HIGHWAY_LENGTH_M))\n",
        "            v = Vehicle(entity_id=f\"v_{i}\", location=(x, 0.0), cpu_freq_mhz=VEHICLE_CPU_FREQ_MHZ, bandwidth_mhz=VEHICLE_BANDWIDTH_MHZ, tx_power_dbm=VEHICLE_TX_POWER_DBM, speed_mps=SPEED_VEHICLES_MPS)\n",
        "            self.vehicles[i] = v\n",
        "\n",
        "    def seed(self, s=None):\n",
        "        np.random.seed(s)\n",
        "        random.seed(s)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        if seed is not None:\n",
        "            self.seed(seed)\n",
        "        self.current_time_s = 0.0\n",
        "        self.all_tasks.clear()\n",
        "        self.task_counter = 0\n",
        "        for v in self.vehicles.values():\n",
        "            v.reset()\n",
        "        for es in self.edges.values():\n",
        "            es.reset()\n",
        "        self.cloud.reset()\n",
        "        for i, v in self.vehicles.items():\n",
        "            num = np.random.randint(0, self.max_tasks_per_vehicle + 1)\n",
        "            for _ in range(num):\n",
        "                cpu = float(np.random.uniform(*CPU_CYCLES_TASK_RANGE_MCY))\n",
        "                data = float(np.random.uniform(*DATA_SIZE_TASK_RANGE_MB))\n",
        "                t = Task(task_id=self.task_counter, cpu_cycles_mcycles=cpu, data_size_mb=data, origin_id=v.entity_id)\n",
        "                self.task_counter += 1\n",
        "                v.add_task_to_queue(t, priority=1)\n",
        "                self.all_tasks[t.task_id] = t\n",
        "        obs = self._get_observation()\n",
        "        return obs, {}  # Gymnasium requires (obs, info)\n",
        "\n",
        "    def _get_observation(self):\n",
        "        obs = np.zeros(self.observation_space.shape, dtype=np.float32)\n",
        "        for i in range(MAX_VEHICLES):\n",
        "            v = self.vehicles.get(i)\n",
        "            idx = 3 * i\n",
        "            if v is not None:\n",
        "                obs[idx] = float(v.location[0] / HIGHWAY_LENGTH_M)\n",
        "                obs[idx+1] = float(v.get_current_workload_mcycles() / (self.max_tasks_per_vehicle * CPU_CYCLES_TASK_RANGE_MCY[1] + 1e-9))\n",
        "                obs[idx+2] = float(len(v.task_queue) / (self.max_tasks_per_vehicle + 1))\n",
        "            # else: pad with 0 (already is)\n",
        "        # global features (unchanged)\n",
        "        avg_edge = np.mean([es.get_current_workload_mcycles() for es in self.edges.values()]) if self.edges else 0.0\n",
        "        obs[-3] = float(avg_edge / (self.max_tasks_per_vehicle * CPU_CYCLES_TASK_RANGE_MCY[1] + 1e-9))\n",
        "        obs[-2] = float(self.cloud.get_current_workload_mcycles() / (self.max_tasks_per_vehicle * CPU_CYCLES_TASK_RANGE_MCY[1] + 1e-9))\n",
        "        avg_vehicle = np.mean([v.get_current_workload_mcycles() for v in self.vehicles.values()]) if self.vehicles else 0.0\n",
        "        obs[-1] = float(avg_vehicle / (self.max_tasks_per_vehicle * CPU_CYCLES_TASK_RANGE_MCY[1] + 1e-9))\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        action = action[:self.num_vehicles]  # Trim to current num_vehicles\n",
        "        assert len(action) == self.num_vehicles\n",
        "        for i, act in enumerate(action):\n",
        "            v = self.vehicles.get(i)\n",
        "            if not v or not v.task_queue:\n",
        "                continue\n",
        "            task_tuple = v.task_queue[0]\n",
        "            if isinstance(task_tuple, tuple):\n",
        "                task, pr = task_tuple\n",
        "            else:\n",
        "                task = task_tuple\n",
        "                pr = 1\n",
        "            task.mark_started(self.current_time_s)  # شروع زمان\n",
        "            if act == 2:  # local\n",
        "                task.offloading_decision = 2\n",
        "                task.assigned_entity = v.entity_id\n",
        "            elif act == 0:  # edge\n",
        "                dists = [(eid, np.linalg.norm(v.location - es.location)) for eid, es in self.edges.items()]\n",
        "                if dists:\n",
        "                    eid, mind = min(dists, key=lambda x: x[1])\n",
        "                    es = self.edges[eid]\n",
        "                    v.start_transmission(task, es, allocated_bw_mhz=v.bandwidth_mhz, tx_power_dbm=v.tx_power_dbm)\n",
        "            elif act == 1:  # other vehicle\n",
        "                candidates = [(j, np.linalg.norm(v.location - v2.location)) for j, v2 in self.vehicles.items() if j != i]\n",
        "                if candidates:\n",
        "                    j, dmin = min(candidates, key=lambda x: x[1])\n",
        "                    v2 = self.vehicles[j]\n",
        "                    v.start_transmission(task, v2, allocated_bw_mhz=min(v.bandwidth_mhz, v2.bandwidth_mhz), tx_power_dbm=v.tx_power_dbm)\n",
        "            elif act == 3:  # cloud\n",
        "                 v.start_transmission(task, self.cloud, allocated_bw_mhz=min(v.bandwidth_mhz, self.cloud.bandwidth_mhz), tx_power_dbm=v.tx_power_dbm)\n",
        "        self._simulate_one_step(DT)\n",
        "        reward = self._compute_reward()\n",
        "        # محاسبه متریک‌ها برای مقاله\n",
        "        completed_tasks = [t for t in self.all_tasks.values() if t.done and t.start_time_s is not None and t.finish_time_s is not None]\n",
        "        avg_completion_time = np.mean([t.finish_time_s - t.start_time_s for t in completed_tasks]) if completed_tasks else 0.0\n",
        "        total_energy = sum(v.energy_consumed_j for v in self.vehicles.values()) + \\\n",
        "                       sum(es.energy_consumed_j for es in self.edges.values()) + \\\n",
        "                       self.cloud.energy_consumed_j\n",
        "        self.current_time_s += DT\n",
        "        obs = self._get_observation()\n",
        "        terminated = (self.current_time_s >= self.episode_duration_s)\n",
        "        truncated = False\n",
        "        info = {\"time\": self.current_time_s, \"avg_completion_time\": avg_completion_time, \"total_energy\": total_energy}\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _simulate_one_step(self, dt):\n",
        "        for v in self.vehicles.values():\n",
        "            v.move(dt)\n",
        "            v.progress_transmissions(dt)\n",
        "            try:\n",
        "                v.process_step(dt, self.current_time_s)\n",
        "            except TypeError:\n",
        "                v.process_step(dt)\n",
        "        for es in self.edges.values():\n",
        "            try:\n",
        "                es.process_step(dt, self.current_time_s)\n",
        "            except TypeError:\n",
        "                es.process_step(dt)\n",
        "        try:\n",
        "            self.cloud.process_step(dt, self.current_time_s)\n",
        "        except TypeError:\n",
        "            self.cloud.process_step(dt)\n",
        "\n",
        "    def _compute_reward(self):\n",
        "        total_energy = sum(v.energy_consumed_j for v in self.vehicles.values()) + \\\n",
        "                       sum(es.energy_consumed_j for es in self.edges.values()) + \\\n",
        "                       self.cloud.energy_consumed_j\n",
        "        total_remaining_deadline = sum((max(0.0, t.deadline_s - (self.current_time_s - (t.start_time_s if t.start_time_s else 0.0))) for t in self.all_tasks.values() if not t.done))\n",
        "        n_tasks = max(1.0, float(len(self.all_tasks)))\n",
        "        n_vehicles = max(1.0, float(len(self.vehicles)))\n",
        "        r = - (WEIGHT_DELAY * (total_remaining_deadline / n_tasks) + WEIGHT_ENERGY * (total_energy / n_vehicles))\n",
        "        return r\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        s = f\"Time={self.current_time_s:.1f}s\\n\"\n",
        "        for i, v in self.vehicles.items():\n",
        "            s += f\"V{i}: pos={v.location[0]:.1f}, q={len(v.task_queue)}, E={v.energy_consumed_j:.4f}\\n\"\n",
        "        print(s)\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b857ea03-36ea-47e3-be73-6d2bfd4586f2",
      "metadata": {
        "id": "b857ea03-36ea-47e3-be73-6d2bfd4586f2",
        "outputId": "c3152fda-9b26-44b2-b431-b86a2d3b5b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "obs shape: (153,)\n",
            "step 0, reward=-1.0005, time=1.0\n",
            "Time=1.0s\n",
            "V0: pos=7118.0, q=0, E=0.0000\n",
            "V1: pos=3085.2, q=3, E=0.0013\n",
            "V2: pos=7545.0, q=3, E=0.0013\n",
            "V3: pos=7735.9, q=3, E=0.0013\n",
            "V4: pos=2199.4, q=3, E=0.0013\n",
            "\n",
            "step 1, reward=-0.4009, time=2.0\n",
            "Time=2.0s\n",
            "V0: pos=7143.0, q=0, E=0.0000\n",
            "V1: pos=3110.2, q=3, E=0.0013\n",
            "V2: pos=7570.0, q=3, E=0.0025\n",
            "V3: pos=7760.9, q=3, E=0.0025\n",
            "V4: pos=2224.4, q=3, E=0.0025\n",
            "\n",
            "step 2, reward=-0.0014, time=3.0\n",
            "Time=3.0s\n",
            "V0: pos=7168.0, q=0, E=0.0000\n",
            "V1: pos=3135.2, q=2, E=0.0025\n",
            "V2: pos=7595.0, q=3, E=0.0038\n",
            "V3: pos=7785.9, q=3, E=0.0038\n",
            "V4: pos=2249.4, q=2, E=0.0038\n",
            "\n",
            "step 3, reward=-0.2018, time=4.0\n",
            "Time=4.0s\n",
            "V0: pos=7193.0, q=0, E=0.0000\n",
            "V1: pos=3160.2, q=3, E=0.0025\n",
            "V2: pos=7620.0, q=3, E=0.0050\n",
            "V3: pos=7810.9, q=2, E=0.0050\n",
            "V4: pos=2274.4, q=2, E=0.0050\n",
            "\n",
            "step 4, reward=-0.0021, time=5.0\n",
            "Time=5.0s\n",
            "V0: pos=7218.0, q=0, E=0.0000\n",
            "V1: pos=3185.2, q=3, E=0.0038\n",
            "V2: pos=7645.0, q=0, E=0.0050\n",
            "V3: pos=7835.9, q=2, E=0.0063\n",
            "V4: pos=2299.4, q=2, E=0.0063\n",
            "\n"
          ]
        }
      ],
      "source": [
        "env = VECEnv(num_vehicles=5, max_tasks_per_vehicle=3, episode_duration_s=20)\n",
        "obs, info = env.reset()\n",
        "print(\"obs shape:\", obs.shape)\n",
        "for step in range(5):\n",
        "    a = env.action_space.sample()\n",
        "    obs, r, terminated, truncated, info = env.step(a)\n",
        "    done = terminated or truncated\n",
        "    print(f\"step {step}, reward={r:.4f}, time={info['time']}\")\n",
        "    env.render()\n",
        "    if done: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfae9554-8b47-4850-a5ef-f7ada253322d",
      "metadata": {
        "scrolled": true,
        "id": "cfae9554-8b47-4850-a5ef-f7ada253322d",
        "outputId": "181e2fcc-0f7e-4519-e90c-e12c88717394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing environment and PPO agent...\n",
            "Using cpu device\n",
            "Training for 20000 timesteps...\n",
            "Logging to results/PPO_8\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | -4.44    |\n",
            "| time/              |          |\n",
            "|    fps             | 39       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 52       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -4.38       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 33          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 123         |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.030069277 |\n",
            "|    clip_fraction        | 0.298       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.3       |\n",
            "|    explained_variance   | 0.372       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.779      |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0628     |\n",
            "|    value_loss           | 0.0141      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 200       |\n",
            "|    ep_rew_mean          | -4.4      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 31        |\n",
            "|    iterations           | 3         |\n",
            "|    time_elapsed         | 194       |\n",
            "|    total_timesteps      | 6144      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0298269 |\n",
            "|    clip_fraction        | 0.298     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -69.3     |\n",
            "|    explained_variance   | 0.772     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.765    |\n",
            "|    n_updates            | 20        |\n",
            "|    policy_gradient_loss | -0.0578   |\n",
            "|    value_loss           | 0.0137    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -4.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 30          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 270         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.033977635 |\n",
            "|    clip_fraction        | 0.323       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.2       |\n",
            "|    explained_variance   | 0.78        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.755      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0636     |\n",
            "|    value_loss           | 0.0154      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -4.41       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 25          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 400         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.034406357 |\n",
            "|    clip_fraction        | 0.336       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.2       |\n",
            "|    explained_variance   | 0.825       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.755      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0622     |\n",
            "|    value_loss           | 0.0137      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -4.42       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 24          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 494         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.033368014 |\n",
            "|    clip_fraction        | 0.314       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.2       |\n",
            "|    explained_variance   | 0.842       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.773      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0605     |\n",
            "|    value_loss           | 0.0158      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -4.41       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 23          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 622         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.036482226 |\n",
            "|    clip_fraction        | 0.338       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.1       |\n",
            "|    explained_variance   | 0.821       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.783      |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.063      |\n",
            "|    value_loss           | 0.0153      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -4.43       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 22          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 735         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.038488586 |\n",
            "|    clip_fraction        | 0.337       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.1       |\n",
            "|    explained_variance   | 0.835       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.735      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.063      |\n",
            "|    value_loss           | 0.0159      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -4.43      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 21         |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 860        |\n",
            "|    total_timesteps      | 18432      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03760916 |\n",
            "|    clip_fraction        | 0.35       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -69.1      |\n",
            "|    explained_variance   | 0.832      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.731     |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.0642    |\n",
            "|    value_loss           | 0.0161     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -4.44      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 20         |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 978        |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03820233 |\n",
            "|    clip_fraction        | 0.342      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -69.1      |\n",
            "|    explained_variance   | 0.841      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.775     |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.0623    |\n",
            "|    value_loss           | 0.0172     |\n",
            "----------------------------------------\n",
            "✅ Model saved at: results/trained_model_ppo.zip\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "import os\n",
        "\n",
        "# پارامترهای آموزش (از کد قبلی‌ت)\n",
        "LEARNING_RATE = 0.0003\n",
        "N_STEPS = 2048\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCHS = 10\n",
        "GAMMA = 0.99\n",
        "GAE_LAMBDA = 0.95\n",
        "CLIP_RANGE = 0.2\n",
        "ENT_COEF = 0.01\n",
        "VF_COEF = 0.5\n",
        "TOTAL_TIMESTEPS = 20000  # کم نگه دار تا سریع باشه، بعداً افزایش بده\n",
        "LOG_INTERVAL = 10\n",
        "SAVE_PATH = \"results/trained_model_ppo.zip\"\n",
        "LOG_DIR = \"results/\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "def train_ppo(total_timesteps=TOTAL_TIMESTEPS, num_vehicles=8, save_path=SAVE_PATH, log_dir=LOG_DIR):\n",
        "    print(\"Initializing environment and PPO agent...\")\n",
        "\n",
        "    # ساخت محیط با DummyVecEnv برای PPO\n",
        "    env = DummyVecEnv([lambda: Monitor(VECEnv(num_vehicles=num_vehicles))])\n",
        "\n",
        "    # مدل PPO\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",\n",
        "        env,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        n_steps=N_STEPS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        n_epochs=N_EPOCHS,\n",
        "        gamma=GAMMA,\n",
        "        gae_lambda=GAE_LAMBDA,\n",
        "        clip_range=CLIP_RANGE,\n",
        "        ent_coef=ENT_COEF,\n",
        "        vf_coef=VF_COEF,\n",
        "        verbose=1,\n",
        "        tensorboard_log=log_dir\n",
        "    )\n",
        "\n",
        "    # ذخیره checkpointها\n",
        "    ckpt_dir = os.path.join(log_dir, \"checkpoints\")\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    checkpoint_callback = CheckpointCallback(save_freq=5000, save_path=ckpt_dir, name_prefix=\"ppo_veh\")\n",
        "\n",
        "    # آموزش\n",
        "    print(f\"Training for {total_timesteps} timesteps...\")\n",
        "    model.learn(total_timesteps=total_timesteps, callback=checkpoint_callback)\n",
        "\n",
        "    # ذخیره مدل\n",
        "    model.save(save_path)\n",
        "    print(f\"✅ Model saved at: {save_path}\")\n",
        "    return model\n",
        "\n",
        "# اجرا کن (اگر قبلاً آموزش دادی، کامنت کن)\n",
        "model = train_ppo(total_timesteps=20000, num_vehicles=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01570477-d4a5-4843-8cfe-65caf28cbd84",
      "metadata": {
        "id": "01570477-d4a5-4843-8cfe-65caf28cbd84",
        "outputId": "ef2df721-8d03-47df-d40e-dde901b4b291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from results/trained_model_ppo.zip\n",
            "Episode 1 (vehicles=10): Completion Time=4.469s, Energy=0.292J, Reward=-5.325\n",
            "Episode 2 (vehicles=10): Completion Time=6.195s, Energy=0.249J, Reward=-4.366\n",
            "Episode 3 (vehicles=10): Completion Time=3.839s, Energy=0.185J, Reward=-3.859\n",
            "\n",
            "Mean for 10 vehicles: Completion Time=4.834s, Energy=0.242J, Reward=-4.517\n",
            "Episode 1 (vehicles=20): Completion Time=7.091s, Energy=0.595J, Reward=-5.237\n",
            "Episode 2 (vehicles=20): Completion Time=6.663s, Energy=0.466J, Reward=-4.404\n",
            "Episode 3 (vehicles=20): Completion Time=7.380s, Energy=0.657J, Reward=-5.563\n",
            "\n",
            "Mean for 20 vehicles: Completion Time=7.045s, Energy=0.573J, Reward=-5.068\n",
            "Episode 1 (vehicles=30): Completion Time=7.475s, Energy=0.918J, Reward=-5.400\n",
            "Episode 2 (vehicles=30): Completion Time=7.203s, Energy=1.001J, Reward=-5.608\n",
            "Episode 3 (vehicles=30): Completion Time=8.775s, Energy=0.813J, Reward=-4.924\n",
            "\n",
            "Mean for 30 vehicles: Completion Time=7.818s, Energy=0.911J, Reward=-5.311\n",
            "Episode 1 (vehicles=40): Completion Time=8.673s, Energy=1.323J, Reward=-5.588\n",
            "Episode 2 (vehicles=40): Completion Time=9.266s, Energy=1.256J, Reward=-5.349\n",
            "Episode 3 (vehicles=40): Completion Time=7.665s, Energy=1.123J, Reward=-5.050\n",
            "\n",
            "Mean for 40 vehicles: Completion Time=8.535s, Energy=1.234J, Reward=-5.329\n",
            "Episode 1 (vehicles=50): Completion Time=10.730s, Energy=1.838J, Reward=-5.891\n",
            "Episode 2 (vehicles=50): Completion Time=9.464s, Energy=1.681J, Reward=-5.593\n",
            "Episode 3 (vehicles=50): Completion Time=12.275s, Energy=1.479J, Reward=-5.191\n",
            "\n",
            "Mean for 50 vehicles: Completion Time=10.823s, Energy=1.666J, Reward=-5.558\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model_path, num_episodes=5, vehicle_ranges=[10, 20, 30, 40, 50], render=False):\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    model = PPO.load(model_path)\n",
        "\n",
        "    results = {\n",
        "        'num_vehicles': vehicle_ranges,\n",
        "        'avg_completion_times': [],\n",
        "        'avg_total_energies': [],\n",
        "        'avg_rewards': []\n",
        "    }\n",
        "\n",
        "    for n in vehicle_ranges:\n",
        "        env = VECEnv(num_vehicles=n, max_tasks_per_vehicle=MAX_TASKS_PER_VEHICLE, episode_duration_s=200)\n",
        "        episode_completion_times = []\n",
        "        episode_total_energies = []\n",
        "        episode_rewards = []\n",
        "\n",
        "        for ep in range(num_episodes):\n",
        "            obs, _ = env.reset()\n",
        "            terminated, truncated = False, False\n",
        "            ep_reward = 0.0\n",
        "            while not (terminated or truncated):\n",
        "                action, _states = model.predict(obs, deterministic=True)\n",
        "                obs, reward, terminated, truncated, info = env.step(action)\n",
        "                ep_reward += reward\n",
        "                if render:\n",
        "                    env.render()\n",
        "\n",
        "            # ذخیره متریک‌های نهایی اپیزود\n",
        "            episode_completion_times.append(info.get('avg_completion_time', 0.0))\n",
        "            episode_total_energies.append(info.get('total_energy', 0.0))\n",
        "            episode_rewards.append(ep_reward)\n",
        "            print(f\"Episode {ep+1} (vehicles={n}): Completion Time={info['avg_completion_time']:.3f}s, Energy={info['total_energy']:.3f}J, Reward={ep_reward:.3f}\")\n",
        "\n",
        "        # میانگین برای این تعداد vehicle\n",
        "        results['avg_completion_times'].append(np.mean(episode_completion_times))\n",
        "        results['avg_total_energies'].append(np.mean(episode_total_energies))\n",
        "        results['avg_rewards'].append(np.mean(episode_rewards))\n",
        "        print(f\"\\nMean for {n} vehicles: Completion Time={results['avg_completion_times'][-1]:.3f}s, Energy={results['avg_total_energies'][-1]:.3f}J, Reward={results['avg_rewards'][-1]:.3f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# اجرا (num_episodes کم نگه دار تا سریع باشه)\n",
        "results = evaluate_model(\"results/trained_model_ppo.zip\", num_episodes=3)\n",
        "import pickle\n",
        "with open(\"results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(results, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773d9e98-1411-476d-aa75-34a57951859f",
      "metadata": {
        "id": "773d9e98-1411-476d-aa75-34a57951859f"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"results.pkl\", \"rb\") as f:\n",
        "    results = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e9747f-1da4-4982-963d-bddc8ea851c7",
      "metadata": {
        "id": "b3e9747f-1da4-4982-963d-bddc8ea851c7",
        "outputId": "705b94f3-9ba1-48a0-a6b9-7bb1296fabe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Chart saved as results_summary.png\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")  # backend بدون رابط گرافیکی\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results_safe(results):\n",
        "    num_vehicles = results['num_vehicles']\n",
        "    avg_completion_times = results['avg_completion_times']\n",
        "    avg_total_energies = results['avg_total_energies']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    axes[0].plot(num_vehicles, avg_completion_times, marker='o')\n",
        "    axes[0].set_xlabel('Number of Vehicles')\n",
        "    axes[0].set_ylabel('Average Completion Time (s)')\n",
        "    axes[0].set_title('Completion Time vs Vehicles')\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    axes[1].plot(num_vehicles, avg_total_energies, marker='o', color='orange')\n",
        "    axes[1].set_xlabel('Number of Vehicles')\n",
        "    axes[1].set_ylabel('Total Energy (J)')\n",
        "    axes[1].set_title('Energy Consumption vs Vehicles')\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"results_summary.png\", dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "plot_results_safe(results)\n",
        "print(\"✅ Chart saved as results_summary.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aff5abc-bd94-4418-b952-86e705c178af",
      "metadata": {
        "id": "9aff5abc-bd94-4418-b952-86e705c178af",
        "outputId": "b9f64590-4009-445c-c338-30326a0f1725"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'VECEnv' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(episode_completion_times), np\u001b[38;5;241m.\u001b[39mmean(episode_total_energies), np\u001b[38;5;241m.\u001b[39mmean(episode_rewards)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# اجرا کن\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m all_results \u001b[38;5;241m=\u001b[39m evaluate_all_methods(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/trained_model_ppo.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mevaluate_all_methods\u001b[1;34m(model_path, num_episodes, vehicle_ranges, methods)\u001b[0m\n\u001b[0;32m     27\u001b[0m all_results \u001b[38;5;241m=\u001b[39m {method: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_vehicles\u001b[39m\u001b[38;5;124m'\u001b[39m: vehicle_ranges, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_completion_times\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_total_energies\u001b[39m\u001b[38;5;124m'\u001b[39m: []} \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m vehicle_ranges:\n\u001b[1;32m---> 30\u001b[0m     env \u001b[38;5;241m=\u001b[39m VECEnv(num_vehicles\u001b[38;5;241m=\u001b[39mn)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMEPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "\u001b[1;31mNameError\u001b[0m: name 'VECEnv' is not defined"
          ]
        }
      ],
      "source": [
        "def evaluate_baselines(env, method, num_episodes=3):\n",
        "    episode_completion_times = []\n",
        "    episode_total_energies = []\n",
        "    episode_rewards = []\n",
        "    for ep in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        terminated, truncated = False, False\n",
        "        ep_reward = 0.0\n",
        "        while not (terminated or truncated):\n",
        "            if method == \"Random\":\n",
        "                action = env.action_space.sample()[:env.num_vehicles]\n",
        "            elif method == \"Local-only\":\n",
        "                action = [2] * env.num_vehicles\n",
        "            elif method == \"Cloud-only\":\n",
        "                action = [3] * env.num_vehicles\n",
        "            elif method == \"Edge-only\":\n",
        "                action = [0] * env.num_vehicles\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            ep_reward += reward\n",
        "        episode_completion_times.append(info.get('avg_completion_time', 0.0))\n",
        "        episode_total_energies.append(info.get('total_energy', 0.0))\n",
        "        episode_rewards.append(ep_reward)\n",
        "    return np.mean(episode_completion_times), np.mean(episode_total_energies), np.mean(episode_rewards)\n",
        "\n",
        "def evaluate_all_methods(model_path, num_episodes=3, vehicle_ranges=[10, 20, 30, 40, 50], methods=[\"MEPPO\", \"Random\", \"Local-only\", \"Cloud-only\"]):\n",
        "    model = PPO.load(model_path) if \"MEPPO\" in methods else None\n",
        "    all_results = {method: {'num_vehicles': vehicle_ranges, 'avg_completion_times': [], 'avg_total_energies': []} for method in methods}\n",
        "\n",
        "    for n in vehicle_ranges:\n",
        "        env = VECEnv(num_vehicles=n)\n",
        "        for method in methods:\n",
        "            if method == \"MEPPO\":\n",
        "                avg_time, avg_energy, _ = evaluate_model_helper(model, env, num_episodes)  # helper for MEPPO\n",
        "            else:\n",
        "                avg_time, avg_energy, _ = evaluate_baselines(env, method, num_episodes)\n",
        "            all_results[method]['avg_completion_times'].append(avg_time)\n",
        "            all_results[method]['avg_total_energies'].append(avg_energy)\n",
        "            print(f\"{method} for {n} vehicles: Time={avg_time:.3f}s, Energy={avg_energy:.3f}J\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def evaluate_model_helper(model, env, num_episodes):\n",
        "    episode_completion_times = []\n",
        "    episode_total_energies = []\n",
        "    episode_rewards = []\n",
        "    for ep in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        terminated, truncated = False, False\n",
        "        ep_reward = 0.0\n",
        "        while not (terminated or truncated):\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            ep_reward += reward\n",
        "        episode_completion_times.append(info.get('avg_completion_time', 0.0))\n",
        "        episode_total_energies.append(info.get('total_energy', 0.0))\n",
        "        episode_rewards.append(ep_reward)\n",
        "    return np.mean(episode_completion_times), np.mean(episode_total_energies), np.mean(episode_rewards)\n",
        "\n",
        "# اجرا کن\n",
        "all_results = evaluate_all_methods(\"results/trained_model_ppo.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c435c8-5b22-413a-afaf-07e49facc4d2",
      "metadata": {
        "id": "51c435c8-5b22-413a-afaf-07e49facc4d2"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")  # backend بدون GUI\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results_comparison(all_results):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    colors = {'MEPPO': 'blue', 'Random': 'green', 'Local-only': 'red', 'Cloud-only': 'orange'}\n",
        "\n",
        "    for method, res in all_results.items():\n",
        "        axes[0].plot(res['num_vehicles'], res['avg_completion_times'], marker='o', label=method, color=colors.get(method))\n",
        "    axes[0].set_xlabel('Number of Vehicles')\n",
        "    axes[0].set_ylabel('Average Completion Time (s)')\n",
        "    axes[0].set_title('Completion Time vs Vehicles')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    for method, res in all_results.items():\n",
        "        axes[1].plot(res['num_vehicles'], res['avg_total_energies'], marker='o', label=method, color=colors.get(method))\n",
        "    axes[1].set_xlabel('Number of Vehicles')\n",
        "    axes[1].set_ylabel('Total Energy (J)')\n",
        "    axes[1].set_title('Energy Consumption vs Vehicles')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"results_comparison.png\", dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(\"✅ Comparison chart saved as results_comparison.png\")\n",
        "\n",
        "# رسم کن\n",
        "plot_results_comparison(all_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd38b45-1ff5-4e32-aae8-e704cbcb3e2d",
      "metadata": {
        "id": "1fd38b45-1ff5-4e32-aae8-e704cbcb3e2d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}