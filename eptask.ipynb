{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2222f50d-9693-4e2f-8176-1072e0bd0a34",
      "metadata": {
        "id": "2222f50d-9693-4e2f-8176-1072e0bd0a34",
        "outputId": "b9cfca19-12fe-41fa-87a2-da9b69862f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (1.2.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.8.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "322c6568-ff4a-4a16-8ace-5dc245f0b02f",
      "metadata": {
        "id": "322c6568-ff4a-4a16-8ace-5dc245f0b02f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from typing import Tuple\n",
        "from collections import deque\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import random\n",
        "import os\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d97c9e0c-fe04-4082-b0fc-4bc41e25c496",
      "metadata": {
        "id": "d97c9e0c-fe04-4082-b0fc-4bc41e25c496"
      },
      "outputs": [],
      "source": [
        "# --- Environment Parameters ---\n",
        "NUM_VEHICLES_TRAIN = 30\n",
        "NUM_EDGE_SERVERS = 8\n",
        "MAX_TASKS_PER_VEHICLE = 10\n",
        "CPU_CYCLES_TASK_MCYCLES = (2, 20)\n",
        "CPU_CYCLES_TASK_RANGE_MCY = (2, 20)\n",
        "DATA_SIZE_TASK_Mbits = (2, 20)\n",
        "DATA_SIZE_TASK_RANGE_MB = (2, 20)\n",
        "VEHICLE_COMP_POWER_MCYCLES_PER_SEC = 1\n",
        "EDGE_COMP_POWER_MCYCLES_PER_SEC = 2\n",
        "CLOUD_COMP_POWER_MCYCLES_PER_SEC = 10\n",
        "\n",
        "# Communication Parameters\n",
        "VEHICLE_BANDWIDTH_MHZ = 100\n",
        "EDGE_BANDWIDTH_MHZ = 100\n",
        "CLOUD_BANDWIDTH_MHZ = 1000\n",
        "VEHICLE_TRANSMIT_POWER_DBM = 1\n",
        "VEHICLE_TX_POWER_DBM = 1\n",
        "VEHICLE_EXECUTION_POWER_DBM = 3\n",
        "EDGE_TX_POWER_DBM = 20\n",
        "CLOUD_TX_POWER_DBM = 30\n",
        "NOISE_POWER_DBM_PER_HZ = -174\n",
        "POWER_CONSUMPTION_COEFFICIENT_XI = 1e-27\n",
        "POWER_CONSUMPTION_COEFFICIENT_GAMMA = 2\n",
        "RSSI_DBM = -75\n",
        "TX_ANTENNA_GAIN_DBI = 20 # Transmit antenna gain\n",
        "RX_ANTENNA_GAIN_DBI = -8 # Receive antenna gain\n",
        "SIGNAL_ATTENUATION_DB = 7 # Signal attenuation caused by obstacles\n",
        "WORKING_FREQUENCY_MHZ = 5000\n",
        "SPEED_VEHICLES_MPS = 25  # m/s\n",
        "MAX_VEHICLES = 50\n",
        "RANDOM_SEED = 0\n",
        "VEHICLE_CPU_FREQ_MHZ = 1\n",
        "EDGE_CPU_FREQ_MHZ = 2\n",
        "CLOUD_CPU_FREQ_MHZ = 10\n",
        "\n",
        "# Mobility Model\n",
        "HIGHWAY_LENGTH_M = 10000\n",
        "VEHICLE_COVERAGE_RANGE_M = 500\n",
        "EDGE_SERVER_COVERAGE_RANGE_M = 1000\n",
        "EDGE_SERVER_LOCATIONS = [(i * HIGHWAY_LENGTH_M / (NUM_EDGE_SERVERS + 1), 0) for i in range(1, NUM_EDGE_SERVERS + 1)]\n",
        "\n",
        "# Problem Formulation Weights\n",
        "WEIGHT_COMPLETION_TIME = 0.5\n",
        "WEIGHT_ENERGY_CONSUMPTION = 0.5\n",
        "WEIGHT_DELAY = 0.5\n",
        "DT = 1\n",
        "\n",
        "# Constraints\n",
        "MAX_TASK_DEADLINE_S = 2 # s\n",
        "MAX_ENERGY_BUDGET_J = 10000 # Joules\n",
        "\n",
        "# --- PPO Agent Parameters ---\n",
        "LEARNING_RATE = 0.0003\n",
        "N_STEPS = 2048\n",
        "BATCH_SIZE = 64\n",
        "N_EPOCHS = 10 # Number of epoch when optimizing the surrogate loss\n",
        "GAMMA = 0.99 # Discount factor\n",
        "GAE_LAMBDA = 0.95 # Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
        "CLIP_RANGE = 0.2 # Clipping parameter, for PPO\n",
        "ENT_COEF = 0.01 # Entropy coefficient for the loss calculation\n",
        "VF_COEF = 0.5 # Value function coefficient for the loss calculation\n",
        "\n",
        "TOTAL_TIMESTEPS = 20000 # Total number of samples to train the agent\n",
        "\n",
        "# --- Training Parameters ---\n",
        "LOG_INTERVAL = 10 # Log every N episodes\n",
        "SAVE_PATH = \"results/trained_model_ppo.zip\"\n",
        "LOG_DIR = \"results/\"\n",
        "LOG_FILE = \"logs.csv\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "# --- Testing Parameters ---\n",
        "NUM_TEST_EPISODES = 100\n",
        "TEST_VEHICLE_COUNTS = [10, 20, 30, 40, 50]\n",
        "TEST_METHODS = [\"MEPPO\", \"DDPG\", \"SAC\", \"Local-only\", \"Offloading-only\", \"Random\"] # Add \"PPO-no-priority\", \"PPO-no-dynamic-power\" for ablation studies if needed\n",
        "\n",
        "# --- Plotting Parameters ---\n",
        "PLOT_TITLE_FONTSIZE = 14\n",
        "PLOT_LABEL_FONTSIZE = 12\n",
        "PLOT_LEGEND_FONTSIZE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "df6b6a94-b817-4c85-9c23-17e5f70fb35e",
      "metadata": {
        "id": "df6b6a94-b817-4c85-9c23-17e5f70fb35e"
      },
      "outputs": [],
      "source": [
        "def dbm_to_mw(dbm: float) -> float:\n",
        "    return 10.0 ** (dbm / 10.0)\n",
        "\n",
        "def mw_to_dbm(mw: float) -> float:\n",
        "    return 10.0 * math.log10(mw)\n",
        "\n",
        "def dbm_to_watt(dbm: float) -> float:\n",
        "    return dbm_to_mw(dbm) * 1e-3\n",
        "\n",
        "def watt_to_dbm(watt: float) -> float:\n",
        "    mw = watt * 1e3\n",
        "    return mw_to_dbm(mw)\n",
        "\n",
        "\n",
        "def calculate_snr_linear(received_power_watt: float, bandwidth_mhz: float,\n",
        "                         interference_watt: float = 0.0,\n",
        "                         noise_dbm_per_hz: float = NOISE_POWER_DBM_PER_HZ) -> float:\n",
        "\n",
        "    bandwidth_hz = bandwidth_mhz * 1e6\n",
        "    noise_w_per_hz = 10 ** ((noise_dbm_per_hz - 30.0) / 10.0)\n",
        "    noise_total_w = noise_w_per_hz * bandwidth_hz\n",
        "    denom = interference_watt + noise_total_w\n",
        "    if denom <= 0:\n",
        "        return 0.0\n",
        "    return received_power_watt / denom\n",
        "\n",
        "def calculate_data_rate_bps(bandwidth_mhz: float, snr_linear: float) -> float:\n",
        "    if snr_linear <= 0:\n",
        "        return 0.0\n",
        "    bandwidth_hz = bandwidth_mhz * 1e6\n",
        "    return bandwidth_hz * math.log2(1.0 + snr_linear)\n",
        "\n",
        "\n",
        "def estimate_link_rate_and_snr(tx_power_dbm: float, distance_m: float, bandwidth_mhz: float,\n",
        "                              tx_gain_dbi: float = None, rx_gain_dbi: float = None,\n",
        "                              signal_attenuation_db: float = None, interference_watt: float = 0.0) -> Tuple[float, float]:\n",
        "\n",
        "    recv_watt = dbm_to_watt(RSSI_DBM)\n",
        "    snr_lin = calculate_snr_linear(recv_watt, bandwidth_mhz, interference_watt=interference_watt)\n",
        "    rate_bps = calculate_data_rate_bps(bandwidth_mhz, snr_lin)\n",
        "    return rate_bps, snr_lin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e3c663ad-eb49-4976-ac7a-f209af85b00f",
      "metadata": {
        "id": "e3c663ad-eb49-4976-ac7a-f209af85b00f"
      },
      "outputs": [],
      "source": [
        "class Task:\n",
        "    def __init__(self, task_id: int, cpu_cycles_mcycles: float, data_size_mb: float,\n",
        "                 deadline_s: float = MAX_TASK_DEADLINE_S, origin_id: int = None):\n",
        "        self.task_id = task_id\n",
        "        self.origin_id = origin_id\n",
        "\n",
        "        self.cpu_cycles_mcycles = float(cpu_cycles_mcycles)\n",
        "        self.data_size_mb = float(data_size_mb)\n",
        "\n",
        "        self.deadline_s = float(deadline_s)\n",
        "        self.priority = 1\n",
        "        self.offloading_decision = None   # 0=edge,1=vehicle,2=local,3=cloud\n",
        "        self.assigned_entity = None\n",
        "\n",
        "        self.remaining_cpu_mcycles = float(cpu_cycles_mcycles)\n",
        "        self.remaining_data_mb = float(data_size_mb)\n",
        "\n",
        "        self.start_time_s = None\n",
        "        self.finish_time_s = None\n",
        "\n",
        "        self.transmission_energy_j = 0.0\n",
        "        self.computation_energy_j = 0.0\n",
        "\n",
        "        self.done = False\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Task(id={self.task_id}, origin={self.origin_id}, cpu_Mc={self.cpu_cycles_mcycles:.2f}, \"\n",
        "                f\"data_MB={self.data_size_mb:.2f}, rem_cpu={self.remaining_cpu_mcycles:.2f}, \"\n",
        "                f\"rem_data={self.remaining_data_mb:.2f}, prio={self.priority}, done={self.done})\")\n",
        "\n",
        "    def mark_started(self, now_s):\n",
        "        if self.start_time_s is None:\n",
        "            self.start_time_s = now_s\n",
        "\n",
        "    def mark_finished(self, now_s):\n",
        "        self.finish_time_s = now_s\n",
        "        self.done = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1e18b373-0bff-401b-8429-c570dad28ea1",
      "metadata": {
        "id": "1e18b373-0bff-401b-8429-c570dad28ea1"
      },
      "outputs": [],
      "source": [
        "class BaseComputeEntity:\n",
        "    def __init__(self, entity_id, location=(0.0, 0.0), cpu_freq_mhz: float = 1.0):\n",
        "        self.entity_id = entity_id\n",
        "        self.location = np.array(location, dtype=float)\n",
        "        self.cpu_freq_mhz = float(cpu_freq_mhz)\n",
        "\n",
        "        self.task_queue = deque()\n",
        "        self.current_transmissions = {}\n",
        "        self.energy_consumed_j = 0.0\n",
        "        self.last_update_time_s = 0.0\n",
        "        self.processed_tasks_history = []\n",
        "\n",
        "    def add_task_to_queue(self, task: Task, priority: int = 1):\n",
        "        task.priority = priority\n",
        "        self.task_queue.append((task, priority))\n",
        "        self.task_queue = deque(sorted(list(self.task_queue), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    def reset(self):\n",
        "        self.task_queue.clear()\n",
        "        self.current_transmissions.clear()\n",
        "        self.energy_consumed_j = 0.0\n",
        "        self.processed_tasks_history.clear()\n",
        "\n",
        "    def get_current_workload_mcycles(self):\n",
        "        return sum(t.remaining_cpu_mcycles for t, _ in self.task_queue)\n",
        "\n",
        "    def process_step(self, dt_s: float, now_s: float):\n",
        "        processed_tasks = []\n",
        "        remaining_time = dt_s\n",
        "        self.last_update_time_s = now_s\n",
        "\n",
        "        while self.task_queue and remaining_time > 1e-12:\n",
        "            task, priority = self.task_queue[0]\n",
        "            cycles_can_do = self.cpu_freq_mhz * remaining_time\n",
        "\n",
        "            if task.remaining_cpu_mcycles <= cycles_can_do:\n",
        "                time_used = task.remaining_cpu_mcycles / (self.cpu_freq_mhz if self.cpu_freq_mhz>0 else 1.0)\n",
        "                f_hz = self.cpu_freq_mhz * 1e6\n",
        "                cycles_done = task.remaining_cpu_mcycles * 1e6\n",
        "                energy_j = POWER_CONSUMPTION_COEFFICIENT_XI * (self.cpu_freq_mhz ** POWER_CONSUMPTION_COEFFICIENT_GAMMA) * task.remaining_cpu_mcycles\n",
        "                energy_j *= 1000.0\n",
        "                task.computation_energy_j += energy_j\n",
        "                self.energy_consumed_j += energy_j\n",
        "\n",
        "                task.remaining_cpu_mcycles = 0.0\n",
        "                task.mark_finished(now_s + time_used)\n",
        "                processed_tasks.append(task)\n",
        "                self.task_queue.popleft()\n",
        "                remaining_time -= time_used\n",
        "            else:\n",
        "                f_hz = self.cpu_freq_mhz * 1e6\n",
        "                cycles_done = cycles_can_do * 1e6\n",
        "                energy_j = POWER_CONSUMPTION_COEFFICIENT_XI * (self.cpu_freq_mhz ** POWER_CONSUMPTION_COEFFICIENT_GAMMA) * task.remaining_cpu_mcycles\n",
        "                energy_j *= 1000.0\n",
        "                task.remaining_cpu_mcycles -= cycles_can_do\n",
        "                task.computation_energy_j += energy_j\n",
        "                self.energy_consumed_j += energy_j\n",
        "                remaining_time = 0.0\n",
        "\n",
        "        return processed_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a526f5a3-d6f3-4621-8189-513fc9d5279b",
      "metadata": {
        "id": "a526f5a3-d6f3-4621-8189-513fc9d5279b"
      },
      "outputs": [],
      "source": [
        "class Vehicle(BaseComputeEntity):\n",
        "    def __init__(self, entity_id, location=(0.0,0.0), cpu_freq_mhz: float = VEHICLE_COMP_POWER_MCYCLES_PER_SEC,\n",
        "                 bandwidth_mhz: float = VEHICLE_BANDWIDTH_MHZ, tx_power_dbm: float = VEHICLE_TRANSMIT_POWER_DBM,\n",
        "                 speed_mps: float = SPEED_VEHICLES_MPS):\n",
        "        super().__init__(entity_id, location, cpu_freq_mhz)\n",
        "        self.bandwidth_mhz = float(bandwidth_mhz)\n",
        "        self.tx_power_dbm = float(tx_power_dbm)\n",
        "        self.tx_power_watt = dbm_to_watt(self.tx_power_dbm)\n",
        "        self.speed_mps = float(speed_mps)\n",
        "        self.outgoing_transmissions = {}\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Vehicle(id={self.entity_id}, loc={self.location.tolist()}, cpu={self.cpu_freq_mhz}MHz)\"\n",
        "\n",
        "    def move(self, dt: float):\n",
        "        self.location[0] = (self.location[0] + self.speed_mps * dt) % HIGHWAY_LENGTH_M\n",
        "\n",
        "    def start_transmission(self, task: Task, dest_entity: BaseComputeEntity, allocated_bw_mhz: float = None, tx_power_dbm: float = None):\n",
        "        if allocated_bw_mhz is None:\n",
        "            allocated_bw_mhz = self.bandwidth_mhz\n",
        "        if tx_power_dbm is None:\n",
        "            tx_power_dbm = self.tx_power_dbm\n",
        "\n",
        "        tx_info = {\n",
        "            'task': task,\n",
        "            'dest': dest_entity,\n",
        "            'allocated_bw_mhz': float(allocated_bw_mhz),\n",
        "            'tx_power_dbm': float(tx_power_dbm),\n",
        "            'progress_mb': 0.0,\n",
        "            'started': True\n",
        "        }\n",
        "        self.outgoing_transmissions[task.task_id] = tx_info\n",
        "        task.offloading_decision = 1 if isinstance(dest_entity, Vehicle) else (0 if dest_entity.__class__.__name__ == 'EdgeServer' else 3)\n",
        "        task.assigned_entity = dest_entity.entity_id\n",
        "\n",
        "    def progress_transmissions(self, dt: float, interference_watt: float = 0.0):\n",
        "        completed_transfers = []\n",
        "        to_remove = []\n",
        "        for tid, info in list(self.outgoing_transmissions.items()):\n",
        "            task = info['task']\n",
        "            dest = info['dest']\n",
        "            bw = info['allocated_bw_mhz']\n",
        "            tx_dbm = info['tx_power_dbm']\n",
        "\n",
        "            distance_m = np.linalg.norm(self.location - dest.location)\n",
        "            rate_bps, snr_lin = estimate_link_rate_and_snr(tx_dbm, distance_m, bw)\n",
        "            rate_mbps = rate_bps / 1e6\n",
        "            data_sent_mb = (rate_mbps * dt) / 8.0\n",
        "\n",
        "            info['progress_mb'] += data_sent_mb\n",
        "            task.remaining_data_mb = max(0.0, task.remaining_data_mb - data_sent_mb)\n",
        "\n",
        "            tx_power_watt = dbm_to_watt(tx_dbm)\n",
        "            energy_j = tx_power_watt * dt\n",
        "            energy_j *= 1000.0\n",
        "            self.energy_consumed_j += energy_j\n",
        "            task.transmission_energy_j += energy_j\n",
        "\n",
        "            if task.remaining_data_mb <= 1e-12:\n",
        "                completed_transfers.append((task, dest))\n",
        "                to_remove.append(tid)\n",
        "\n",
        "        for tid in to_remove:\n",
        "            del self.outgoing_transmissions[tid]\n",
        "\n",
        "        for task, dest in completed_transfers:\n",
        "            dest.add_task_to_queue(task, priority=task.priority)\n",
        "\n",
        "        return completed_transfers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "aa95f51b-3ac6-4a29-9db8-92fee1eb9165",
      "metadata": {
        "id": "aa95f51b-3ac6-4a29-9db8-92fee1eb9165"
      },
      "outputs": [],
      "source": [
        "class EdgeServer(BaseComputeEntity):\n",
        "    def __init__(self, entity_id, location=(0.0, 0.0), cpu_freq_mhz: float = EDGE_COMP_POWER_MCYCLES_PER_SEC,\n",
        "                 bandwidth_mhz: float = EDGE_BANDWIDTH_MHZ, tx_power_dbm: float = EDGE_TX_POWER_DBM):\n",
        "        super().__init__(entity_id, location, cpu_freq_mhz)\n",
        "        self.bandwidth_mhz = float(bandwidth_mhz)\n",
        "        self.tx_power_dbm = float(tx_power_dbm)\n",
        "        self.tx_power_watt = dbm_to_watt(self.tx_power_dbm)\n",
        "        self.connected_vehicles = set()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"EdgeServer(id={self.entity_id}, loc={self.location.tolist()}, cpu={self.cpu_freq_mhz}MHz)\"\n",
        "\n",
        "\n",
        "class CloudServer(BaseComputeEntity):\n",
        "    def __init__(self, entity_id=\"cloud_0\", location=(HIGHWAY_LENGTH_M/2, 5000.0), cpu_freq_mhz: float = CLOUD_COMP_POWER_MCYCLES_PER_SEC,\n",
        "                 bandwidth_mhz: float = CLOUD_BANDWIDTH_MHZ, tx_power_dbm: float = CLOUD_TX_POWER_DBM):\n",
        "        super().__init__(entity_id, location, cpu_freq_mhz)\n",
        "        self.bandwidth_mhz = float(bandwidth_mhz)\n",
        "        self.tx_power_dbm = float(tx_power_dbm)\n",
        "        self.tx_power_watt = dbm_to_watt(self.tx_power_dbm)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"CloudServer(id={self.entity_id}, loc={self.location.tolist()}, cpu={self.cpu_freq_mhz}MHz)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c746b977-0443-4f5e-b4d5-e99cf17f1d94",
      "metadata": {
        "id": "c746b977-0443-4f5e-b4d5-e99cf17f1d94"
      },
      "outputs": [],
      "source": [
        "class VECEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, num_vehicles: int = 10, max_tasks_per_vehicle: int = MAX_TASKS_PER_VEHICLE, episode_duration_s: int = 200):\n",
        "        super().__init__()\n",
        "        self.num_vehicles = min(num_vehicles, MAX_VEHICLES)  # محدود به max\n",
        "        self.max_tasks_per_vehicle = max_tasks_per_vehicle\n",
        "        self.episode_duration_s = episode_duration_s\n",
        "        self.current_time_s = 0.0\n",
        "        self.vehicles = {}\n",
        "        self.edges = {}\n",
        "        self.cloud = None\n",
        "        self.all_tasks = {}\n",
        "        self.task_counter = 0\n",
        "        self._init_entities()\n",
        "        obs_dim = 3 * MAX_VEHICLES + 3  # ثابت برای max\n",
        "        self.observation_space = spaces.Box(low=0.0, high=1.0, shape=(obs_dim,), dtype=np.float32)\n",
        "        self.action_space = spaces.MultiDiscrete([4] * MAX_VEHICLES)  # ثابت برای max\n",
        "        self.seed(RANDOM_SEED)\n",
        "\n",
        "    def _init_entities(self):\n",
        "        for i, loc in enumerate(EDGE_SERVER_LOCATIONS):\n",
        "            es = EdgeServer(entity_id=f\"es_{i}\", location=loc, cpu_freq_mhz=EDGE_CPU_FREQ_MHZ, bandwidth_mhz=EDGE_BANDWIDTH_MHZ, tx_power_dbm=EDGE_TX_POWER_DBM)\n",
        "            self.edges[i] = es\n",
        "        self.cloud = CloudServer(entity_id=\"cloud_0\", location=(HIGHWAY_LENGTH_M/2, 5000.0), cpu_freq_mhz=CLOUD_CPU_FREQ_MHZ, bandwidth_mhz=CLOUD_BANDWIDTH_MHZ, tx_power_dbm=CLOUD_TX_POWER_DBM)\n",
        "        for i in range(self.num_vehicles):\n",
        "            x = float(np.random.uniform(0, HIGHWAY_LENGTH_M))\n",
        "            v = Vehicle(entity_id=f\"v_{i}\", location=(x, 0.0), cpu_freq_mhz=VEHICLE_CPU_FREQ_MHZ, bandwidth_mhz=VEHICLE_BANDWIDTH_MHZ, tx_power_dbm=VEHICLE_TX_POWER_DBM, speed_mps=SPEED_VEHICLES_MPS)\n",
        "            self.vehicles[i] = v\n",
        "\n",
        "    def seed(self, s=None):\n",
        "        np.random.seed(s)\n",
        "        random.seed(s)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        if seed is not None:\n",
        "            self.seed(seed)\n",
        "        self.current_time_s = 0.0\n",
        "        self.all_tasks.clear()\n",
        "        self.task_counter = 0\n",
        "        for v in self.vehicles.values():\n",
        "            v.reset()\n",
        "        for es in self.edges.values():\n",
        "            es.reset()\n",
        "        self.cloud.reset()\n",
        "        for i, v in self.vehicles.items():\n",
        "            num = np.random.randint(0, self.max_tasks_per_vehicle + 1)\n",
        "            for _ in range(num):\n",
        "                cpu = float(np.random.uniform(*CPU_CYCLES_TASK_RANGE_MCY))\n",
        "                data = float(np.random.uniform(*DATA_SIZE_TASK_RANGE_MB))\n",
        "                t = Task(task_id=self.task_counter, cpu_cycles_mcycles=cpu, data_size_mb=data, origin_id=v.entity_id)\n",
        "                self.task_counter += 1\n",
        "                v.add_task_to_queue(t, priority=1)\n",
        "                self.all_tasks[t.task_id] = t\n",
        "        obs = self._get_observation()\n",
        "        return obs, {}\n",
        "\n",
        "    def _get_observation(self):\n",
        "        obs = np.zeros(self.observation_space.shape, dtype=np.float32)\n",
        "        for i in range(MAX_VEHICLES):\n",
        "            v = self.vehicles.get(i)\n",
        "            idx = 3 * i\n",
        "            if v is not None:\n",
        "                obs[idx] = float(v.location[0] / HIGHWAY_LENGTH_M)\n",
        "                obs[idx+1] = float(v.get_current_workload_mcycles() / (self.max_tasks_per_vehicle * CPU_CYCLES_TASK_RANGE_MCY[1] + 1e-9))\n",
        "                obs[idx+2] = float(len(v.task_queue) / (self.max_tasks_per_vehicle + 1))\n",
        "            # else: pad with 0 (already is)\n",
        "        # global features (unchanged)\n",
        "        avg_edge = np.mean([es.get_current_workload_mcycles() for es in self.edges.values()]) if self.edges else 0.0\n",
        "        obs[-3] = float(avg_edge / (self.max_tasks_per_vehicle * CPU_CYCLES_TASK_RANGE_MCY[1] + 1e-9))\n",
        "        obs[-2] = float(self.cloud.get_current_workload_mcycles() / (self.max_tasks_per_vehicle * CPU_CYCLES_TASK_RANGE_MCY[1] + 1e-9))\n",
        "        avg_vehicle = np.mean([v.get_current_workload_mcycles() for v in self.vehicles.values()]) if self.vehicles else 0.0\n",
        "        obs[-1] = float(avg_vehicle / (self.max_tasks_per_vehicle * CPU_CYCLES_TASK_RANGE_MCY[1] + 1e-9))\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        action = action[:self.num_vehicles]  # Trim to current num_vehicles\n",
        "        assert len(action) == self.num_vehicles\n",
        "        for i, act in enumerate(action):\n",
        "            v = self.vehicles.get(i)\n",
        "            if not v or not v.task_queue:\n",
        "                continue\n",
        "            task_tuple = v.task_queue[0]\n",
        "            if isinstance(task_tuple, tuple):\n",
        "                task, pr = task_tuple\n",
        "            else:\n",
        "                task = task_tuple\n",
        "                pr = 1\n",
        "            task.mark_started(self.current_time_s)  # شروع زمان\n",
        "            if act == 2:  # local\n",
        "                task.offloading_decision = 2\n",
        "                task.assigned_entity = v.entity_id\n",
        "            elif act == 0:  # edge\n",
        "                dists = [(eid, np.linalg.norm(v.location - es.location)) for eid, es in self.edges.items()]\n",
        "                if dists:\n",
        "                    eid, mind = min(dists, key=lambda x: x[1])\n",
        "                    es = self.edges[eid]\n",
        "                    v.start_transmission(task, es, allocated_bw_mhz=v.bandwidth_mhz, tx_power_dbm=v.tx_power_dbm)\n",
        "            elif act == 1:  # other vehicle\n",
        "                candidates = [(j, np.linalg.norm(v.location - v2.location)) for j, v2 in self.vehicles.items() if j != i]\n",
        "                if candidates:\n",
        "                    j, dmin = min(candidates, key=lambda x: x[1])\n",
        "                    v2 = self.vehicles[j]\n",
        "                    v.start_transmission(task, v2, allocated_bw_mhz=min(v.bandwidth_mhz, v2.bandwidth_mhz), tx_power_dbm=v.tx_power_dbm)\n",
        "            elif act == 3:  # cloud\n",
        "                 v.start_transmission(task, self.cloud, allocated_bw_mhz=min(v.bandwidth_mhz, self.cloud.bandwidth_mhz), tx_power_dbm=v.tx_power_dbm)\n",
        "        self._simulate_one_step(DT)\n",
        "        reward = self._compute_reward()\n",
        "\n",
        "        completed_tasks = [t for t in self.all_tasks.values() if t.done and t.start_time_s is not None and t.finish_time_s is not None]\n",
        "        avg_completion_time = np.mean([t.finish_time_s - t.start_time_s for t in completed_tasks]) if completed_tasks else 0.0\n",
        "        total_energy = sum(v.energy_consumed_j for v in self.vehicles.values()) + \\\n",
        "                       sum(es.energy_consumed_j for es in self.edges.values()) + \\\n",
        "                       self.cloud.energy_consumed_j\n",
        "        self.current_time_s += DT\n",
        "        obs = self._get_observation()\n",
        "        terminated = (self.current_time_s >= self.episode_duration_s)\n",
        "        truncated = False\n",
        "        info = {\"time\": self.current_time_s, \"avg_completion_time\": avg_completion_time, \"total_energy\": total_energy}\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _simulate_one_step(self, dt):\n",
        "        for v in self.vehicles.values():\n",
        "            v.move(dt)\n",
        "            v.progress_transmissions(dt)\n",
        "            try:\n",
        "                v.process_step(dt, self.current_time_s)\n",
        "            except TypeError:\n",
        "                v.process_step(dt)\n",
        "        for es in self.edges.values():\n",
        "            try:\n",
        "                es.process_step(dt, self.current_time_s)\n",
        "            except TypeError:\n",
        "                es.process_step(dt)\n",
        "        try:\n",
        "            self.cloud.process_step(dt, self.current_time_s)\n",
        "        except TypeError:\n",
        "            self.cloud.process_step(dt)\n",
        "\n",
        "    def _compute_reward(self):\n",
        "        total_energy = sum(v.energy_consumed_j for v in self.vehicles.values()) + \\\n",
        "                       sum(es.energy_consumed_j for es in self.edges.values()) + \\\n",
        "                       self.cloud.energy_consumed_j\n",
        "        total_remaining_deadline = sum((max(0.0, t.deadline_s - (self.current_time_s - (t.start_time_s if t.start_time_s else 0.0))) for t in self.all_tasks.values() if not t.done))\n",
        "        n_tasks = max(1.0, float(len(self.all_tasks)))\n",
        "        n_vehicles = max(1.0, float(len(self.vehicles)))\n",
        "        r = - (WEIGHT_DELAY * (total_remaining_deadline / n_tasks) + WEIGHT_ENERGY * (total_energy / n_vehicles))\n",
        "        return r\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        s = f\"Time={self.current_time_s:.1f}s\\n\"\n",
        "        for i, v in self.vehicles.items():\n",
        "            s += f\"V{i}: pos={v.location[0]:.1f}, q={len(v.task_queue)}, E={v.energy_consumed_j:.4f}\\n\"\n",
        "        print(s)\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "b857ea03-36ea-47e3-be73-6d2bfd4586f2",
      "metadata": {
        "id": "b857ea03-36ea-47e3-be73-6d2bfd4586f2",
        "outputId": "9adb7165-ec17-47f6-c124-175760597823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs shape: (153,)\n",
            "step 0, reward=-1.3777, time=1.0\n",
            "Time=1.0s\n",
            "V0: pos=6530.0, q=0, E=0.0000\n",
            "V1: pos=7731.7, q=3, E=1.2589\n",
            "V2: pos=2260.7, q=2, E=0.0000\n",
            "V3: pos=2974.6, q=2, E=1.2589\n",
            "V4: pos=5673.9, q=3, E=1.2589\n",
            "\n",
            "step 1, reward=-1.3312, time=2.0\n",
            "Time=2.0s\n",
            "V0: pos=6555.0, q=0, E=0.0000\n",
            "V1: pos=7756.7, q=3, E=2.5179\n",
            "V2: pos=2285.7, q=3, E=1.2589\n",
            "V3: pos=2999.6, q=3, E=2.5179\n",
            "V4: pos=5698.9, q=3, E=2.5179\n",
            "\n",
            "step 2, reward=-1.2589, time=3.0\n",
            "Time=3.0s\n",
            "V0: pos=6580.0, q=2, E=0.0000\n",
            "V1: pos=7781.7, q=2, E=3.7768\n",
            "V2: pos=2310.7, q=3, E=1.2589\n",
            "V3: pos=3024.6, q=3, E=3.7768\n",
            "V4: pos=5723.9, q=3, E=3.7768\n",
            "\n",
            "step 3, reward=-1.8625, time=4.0\n",
            "Time=4.0s\n",
            "V0: pos=6605.0, q=1, E=1.2589\n",
            "V1: pos=7806.7, q=2, E=3.7768\n",
            "V2: pos=2335.7, q=3, E=2.5179\n",
            "V3: pos=3049.6, q=3, E=5.0357\n",
            "V4: pos=5748.9, q=3, E=5.0357\n",
            "\n",
            "step 4, reward=-2.4902, time=5.0\n",
            "Time=5.0s\n",
            "V0: pos=6630.0, q=1, E=2.5179\n",
            "V1: pos=7831.7, q=2, E=3.7768\n",
            "V2: pos=2360.7, q=4, E=2.5179\n",
            "V3: pos=3074.6, q=3, E=6.2946\n",
            "V4: pos=5773.9, q=3, E=6.2946\n",
            "\n"
          ]
        }
      ],
      "source": [
        "env = VECEnv(num_vehicles=5, max_tasks_per_vehicle=3, episode_duration_s=20)\n",
        "obs, info = env.reset()\n",
        "print(\"obs shape:\", obs.shape)\n",
        "for step in range(5):\n",
        "    a = env.action_space.sample()\n",
        "    obs, r, terminated, truncated, info = env.step(a)\n",
        "    done = terminated or truncated\n",
        "    print(f\"step {step}, reward={r:.4f}, time={info['time']}\")\n",
        "    env.render()\n",
        "    if done: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cfae9554-8b47-4850-a5ef-f7ada253322d",
      "metadata": {
        "scrolled": true,
        "id": "cfae9554-8b47-4850-a5ef-f7ada253322d",
        "outputId": "32700244-8a15-456c-b984-ba9c9bf860ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing environment and PPO agent...\n",
            "Using cpu device\n",
            "Training for 20000 timesteps...\n",
            "Logging to results/PPO_3\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 200       |\n",
            "|    ep_rew_mean     | -1.95e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 77        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 26        |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.92e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 66          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014407932 |\n",
            "|    clip_fraction        | 0.184       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.3       |\n",
            "|    explained_variance   | 0.000774    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.98e+03    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0423     |\n",
            "|    value_loss           | 2.43e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.95e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 62          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 97          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014338374 |\n",
            "|    clip_fraction        | 0.149       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.3       |\n",
            "|    explained_variance   | 0.0034      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.19e+04    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0375     |\n",
            "|    value_loss           | 2.39e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.96e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 61          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 133         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015635815 |\n",
            "|    clip_fraction        | 0.172       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.3       |\n",
            "|    explained_variance   | 0.00108     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.38e+04    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0436     |\n",
            "|    value_loss           | 2.59e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.96e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 60          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 168         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015300771 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.3       |\n",
            "|    explained_variance   | 0.000558    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.18e+04    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0399     |\n",
            "|    value_loss           | 2.37e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.99e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 60          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 204         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014054516 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.2       |\n",
            "|    explained_variance   | 0.000281    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.12e+04    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0389     |\n",
            "|    value_loss           | 2.5e+04     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.98e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 59          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 241         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015956819 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.2       |\n",
            "|    explained_variance   | 0.000411    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.28e+04    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0415     |\n",
            "|    value_loss           | 2.71e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -2e+03      |\n",
            "| time/                   |             |\n",
            "|    fps                  | 59          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 276         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017725602 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.2       |\n",
            "|    explained_variance   | 0.000208    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.05e+04    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0424     |\n",
            "|    value_loss           | 2.25e+04    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -1.99e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 59         |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 311        |\n",
            "|    total_timesteps      | 18432      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01431682 |\n",
            "|    clip_fraction        | 0.157      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -69.2      |\n",
            "|    explained_variance   | 0.000223   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.31e+04   |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.0366    |\n",
            "|    value_loss           | 2.56e+04   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.99e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 59          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 346         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015982797 |\n",
            "|    clip_fraction        | 0.184       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -69.2       |\n",
            "|    explained_variance   | 0.000127    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.88e+03    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0453     |\n",
            "|    value_loss           | 2.41e+04    |\n",
            "-----------------------------------------\n",
            " Model saved at: results/trained_model_ppo.zip\n"
          ]
        }
      ],
      "source": [
        "def train_ppo(total_timesteps=TOTAL_TIMESTEPS, num_vehicles=8, save_path=SAVE_PATH, log_dir=LOG_DIR):\n",
        "    print(\"Initializing environment and PPO agent...\")\n",
        "\n",
        "    env = DummyVecEnv([lambda: Monitor(VECEnv(num_vehicles=num_vehicles))])\n",
        "\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",\n",
        "        env,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        n_steps=N_STEPS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        n_epochs=N_EPOCHS,\n",
        "        gamma=GAMMA,\n",
        "        gae_lambda=GAE_LAMBDA,\n",
        "        clip_range=CLIP_RANGE,\n",
        "        ent_coef=ENT_COEF,\n",
        "        vf_coef=VF_COEF,\n",
        "        verbose=1,\n",
        "        tensorboard_log=log_dir\n",
        "    )\n",
        "\n",
        "    ckpt_dir = os.path.join(log_dir, \"checkpoints\")\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "    checkpoint_callback = CheckpointCallback(save_freq=5000, save_path=ckpt_dir, name_prefix=\"ppo_veh\")\n",
        "\n",
        "    print(f\"Training for {total_timesteps} timesteps...\")\n",
        "    model.learn(total_timesteps=total_timesteps, callback=checkpoint_callback)\n",
        "\n",
        "    model.save(save_path)\n",
        "    print(f\" Model saved at: {save_path}\")\n",
        "    return model\n",
        "\n",
        "model = train_ppo(total_timesteps=20000, num_vehicles=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "01570477-d4a5-4843-8cfe-65caf28cbd84",
      "metadata": {
        "id": "01570477-d4a5-4843-8cfe-65caf28cbd84",
        "outputId": "060bb82a-0910-4dea-891e-168011d1d5e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from results/trained_model_ppo.zip\n",
            "Episode 1 (vehicles=10): Completion Time=9.778s, Energy=313.472J, Reward=-2662.246\n",
            "Episode 2 (vehicles=10): Completion Time=7.882s, Energy=180.026J, Reward=-1623.681\n",
            "Episode 3 (vehicles=10): Completion Time=6.344s, Energy=162.401J, Reward=-1512.151\n",
            "\n",
            "Mean for 10 vehicles: Completion Time=8.002s, Energy=218.633J, Reward=-1932.693\n",
            "Episode 1 (vehicles=20): Completion Time=7.643s, Energy=577.847J, Reward=-2608.277\n",
            "Episode 2 (vehicles=20): Completion Time=6.734s, Energy=387.749J, Reward=-1748.929\n",
            "Episode 3 (vehicles=20): Completion Time=9.685s, Energy=688.632J, Reward=-3013.307\n",
            "\n",
            "Mean for 20 vehicles: Completion Time=8.021s, Energy=551.409J, Reward=-2456.838\n",
            "Episode 1 (vehicles=30): Completion Time=8.067s, Energy=741.507J, Reward=-2249.388\n",
            "Episode 2 (vehicles=30): Completion Time=7.722s, Energy=784.311J, Reward=-2307.211\n",
            "Episode 3 (vehicles=30): Completion Time=10.189s, Energy=621.909J, Reward=-1810.605\n",
            "\n",
            "Mean for 30 vehicles: Completion Time=8.660s, Energy=715.909J, Reward=-2122.401\n",
            "Episode 1 (vehicles=40): Completion Time=8.996s, Energy=1101.560J, Reward=-2476.517\n",
            "Episode 2 (vehicles=40): Completion Time=10.030s, Energy=887.542J, Reward=-1936.685\n",
            "Episode 3 (vehicles=40): Completion Time=7.733s, Energy=946.712J, Reward=-2145.159\n",
            "\n",
            "Mean for 40 vehicles: Completion Time=8.920s, Energy=978.605J, Reward=-2186.120\n",
            "Episode 1 (vehicles=50): Completion Time=11.183s, Energy=1529.594J, Reward=-2655.454\n",
            "Episode 2 (vehicles=50): Completion Time=11.502s, Energy=1067.569J, Reward=-1916.538\n",
            "Episode 3 (vehicles=50): Completion Time=11.213s, Energy=1197.238J, Reward=-2076.293\n",
            "\n",
            "Mean for 50 vehicles: Completion Time=11.300s, Energy=1264.800J, Reward=-2216.095\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model_path, num_episodes=5, vehicle_ranges=[10, 20, 30, 40, 50], render=False):\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    model = PPO.load(model_path)\n",
        "\n",
        "    results = {\n",
        "        'num_vehicles': vehicle_ranges,\n",
        "        'avg_completion_times': [],\n",
        "        'avg_total_energies': [],\n",
        "        'avg_rewards': []\n",
        "    }\n",
        "\n",
        "    for n in vehicle_ranges:\n",
        "        env = VECEnv(num_vehicles=n, max_tasks_per_vehicle=MAX_TASKS_PER_VEHICLE, episode_duration_s=200)\n",
        "        episode_completion_times = []\n",
        "        episode_total_energies = []\n",
        "        episode_rewards = []\n",
        "\n",
        "        for ep in range(num_episodes):\n",
        "            obs, _ = env.reset()\n",
        "            terminated, truncated = False, False\n",
        "            ep_reward = 0.0\n",
        "            while not (terminated or truncated):\n",
        "                action, _states = model.predict(obs, deterministic=True)\n",
        "                obs, reward, terminated, truncated, info = env.step(action)\n",
        "                ep_reward += reward\n",
        "                if render:\n",
        "                    env.render()\n",
        "\n",
        "            episode_completion_times.append(info.get('avg_completion_time', 0.0))\n",
        "            episode_total_energies.append(info.get('total_energy', 0.0))\n",
        "            episode_rewards.append(ep_reward)\n",
        "            print(f\"Episode {ep+1} (vehicles={n}): Completion Time={info['avg_completion_time']:.3f}s, Energy={info['total_energy']:.3f}J, Reward={ep_reward:.3f}\")\n",
        "\n",
        "\n",
        "        results['avg_completion_times'].append(np.mean(episode_completion_times))\n",
        "        results['avg_total_energies'].append(np.mean(episode_total_energies))\n",
        "        results['avg_rewards'].append(np.mean(episode_rewards))\n",
        "        print(f\"\\nMean for {n} vehicles: Completion Time={results['avg_completion_times'][-1]:.3f}s, Energy={results['avg_total_energies'][-1]:.3f}J, Reward={results['avg_rewards'][-1]:.3f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "results = evaluate_model(\"results/trained_model_ppo.zip\", num_episodes=3)\n",
        "import pickle\n",
        "with open(\"results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(results, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773d9e98-1411-476d-aa75-34a57951859f",
      "metadata": {
        "id": "773d9e98-1411-476d-aa75-34a57951859f"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"results.pkl\", \"rb\") as f:\n",
        "    results = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "b3e9747f-1da4-4982-963d-bddc8ea851c7",
      "metadata": {
        "id": "b3e9747f-1da4-4982-963d-bddc8ea851c7",
        "outputId": "7c050b81-c0a3-48ae-a35e-6466d8b99e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Chart saved as results_summary.png\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results_safe(results):\n",
        "    num_vehicles = results['num_vehicles']\n",
        "    avg_completion_times = results['avg_completion_times']\n",
        "    avg_total_energies = results['avg_total_energies']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    axes[0].plot(num_vehicles, avg_completion_times, marker='o')\n",
        "    axes[0].set_xlabel('Number of Vehicles')\n",
        "    axes[0].set_ylabel('Average Completion Time (s)')\n",
        "    axes[0].set_title('Completion Time vs Vehicles')\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    axes[1].plot(num_vehicles, avg_total_energies, marker='o', color='orange')\n",
        "    axes[1].set_xlabel('Number of Vehicles')\n",
        "    axes[1].set_ylabel('Total Energy (J)')\n",
        "    axes[1].set_title('Energy Consumption vs Vehicles')\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"results_summary.png\", dpi=150)\n",
        "    plt.close(fig)\n",
        "\n",
        "plot_results_safe(results)\n",
        "print(\" Chart saved as results_summary.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9aff5abc-bd94-4418-b952-86e705c178af",
      "metadata": {
        "id": "9aff5abc-bd94-4418-b952-86e705c178af",
        "outputId": "c5dce864-624a-4be2-8ccf-8d925751608f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEPPO for 10 vehicles: Time=11.474s, Energy=230.383J\n",
            "Random for 10 vehicles: Time=11.211s, Energy=236.678J\n",
            "Local-only for 10 vehicles: Time=10.667s, Energy=0.000J\n",
            "Cloud-only for 10 vehicles: Time=5.304s, Energy=255.982J\n",
            "MEPPO for 20 vehicles: Time=11.422s, Energy=582.882J\n",
            "Random for 20 vehicles: Time=11.257s, Energy=441.044J\n",
            "Local-only for 20 vehicles: Time=10.879s, Energy=0.000J\n",
            "Cloud-only for 20 vehicles: Time=9.102s, Energy=737.730J\n",
            "MEPPO for 30 vehicles: Time=10.460s, Energy=739.829J\n",
            "Random for 30 vehicles: Time=14.645s, Energy=817.462J\n",
            "Local-only for 30 vehicles: Time=10.878s, Energy=0.000J\n",
            "Cloud-only for 30 vehicles: Time=11.739s, Energy=1357.541J\n",
            "MEPPO for 40 vehicles: Time=10.587s, Energy=938.739J\n",
            "Random for 40 vehicles: Time=15.352s, Energy=1221.997J\n",
            "Local-only for 40 vehicles: Time=10.536s, Energy=0.000J\n",
            "Cloud-only for 40 vehicles: Time=12.809s, Energy=1827.120J\n",
            "MEPPO for 50 vehicles: Time=10.716s, Energy=1276.970J\n",
            "Random for 50 vehicles: Time=17.804s, Energy=1721.790J\n",
            "Local-only for 50 vehicles: Time=10.344s, Energy=0.000J\n",
            "Cloud-only for 50 vehicles: Time=14.906s, Energy=2653.815J\n"
          ]
        }
      ],
      "source": [
        "def evaluate_baselines(env, method, num_episodes=3):\n",
        "    episode_completion_times = []\n",
        "    episode_total_energies = []\n",
        "    episode_rewards = []\n",
        "    for ep in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        terminated, truncated = False, False\n",
        "        ep_reward = 0.0\n",
        "        while not (terminated or truncated):\n",
        "            if method == \"Random\":\n",
        "                action = env.action_space.sample()[:env.num_vehicles]\n",
        "            elif method == \"Local-only\":\n",
        "                action = [2] * env.num_vehicles\n",
        "            elif method == \"Cloud-only\":\n",
        "                action = [3] * env.num_vehicles\n",
        "            elif method == \"Edge-only\":\n",
        "                action = [0] * env.num_vehicles\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            ep_reward += reward\n",
        "        episode_completion_times.append(info.get('avg_completion_time', 0.0))\n",
        "        episode_total_energies.append(info.get('total_energy', 0.0))\n",
        "        episode_rewards.append(ep_reward)\n",
        "    return np.mean(episode_completion_times), np.mean(episode_total_energies), np.mean(episode_rewards)\n",
        "\n",
        "def evaluate_all_methods(model_path, num_episodes=3, vehicle_ranges=[10, 20, 30, 40, 50], methods=[\"MEPPO\", \"Random\", \"Local-only\", \"Cloud-only\"]):\n",
        "    model = PPO.load(model_path) if \"MEPPO\" in methods else None\n",
        "    all_results = {method: {'num_vehicles': vehicle_ranges, 'avg_completion_times': [], 'avg_total_energies': []} for method in methods}\n",
        "\n",
        "    for n in vehicle_ranges:\n",
        "        env = VECEnv(num_vehicles=n)\n",
        "        for method in methods:\n",
        "            if method == \"MEPPO\":\n",
        "                avg_time, avg_energy, _ = evaluate_model_helper(model, env, num_episodes)  # helper for MEPPO\n",
        "            else:\n",
        "                avg_time, avg_energy, _ = evaluate_baselines(env, method, num_episodes)\n",
        "            all_results[method]['avg_completion_times'].append(avg_time)\n",
        "            all_results[method]['avg_total_energies'].append(avg_energy)\n",
        "            print(f\"{method} for {n} vehicles: Time={avg_time:.3f}s, Energy={avg_energy:.3f}J\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def evaluate_model_helper(model, env, num_episodes):\n",
        "    episode_completion_times = []\n",
        "    episode_total_energies = []\n",
        "    episode_rewards = []\n",
        "    for ep in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        terminated, truncated = False, False\n",
        "        ep_reward = 0.0\n",
        "        while not (terminated or truncated):\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            ep_reward += reward\n",
        "        episode_completion_times.append(info.get('avg_completion_time', 0.0))\n",
        "        episode_total_energies.append(info.get('total_energy', 0.0))\n",
        "        episode_rewards.append(ep_reward)\n",
        "    return np.mean(episode_completion_times), np.mean(episode_total_energies), np.mean(episode_rewards)\n",
        "\n",
        "\n",
        "all_results = evaluate_all_methods(\"results/trained_model_ppo.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "51c435c8-5b22-413a-afaf-07e49facc4d2",
      "metadata": {
        "id": "51c435c8-5b22-413a-afaf-07e49facc4d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191f154f-370a-4979-a948-27bb51864122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Comparison chart saved as results_comparison_bar.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results_comparison(all_results):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    colors = {'MEPPO': 'blue', 'Random': 'green', 'Local-only': 'red', 'Cloud-only': 'orange'}\n",
        "    methods = list(all_results.keys())\n",
        "    num_vehicles = all_results['MEPPO']['num_vehicles']\n",
        "    bar_width = 2\n",
        "    index = np.arange(len(num_vehicles))\n",
        "\n",
        "    # Completion Time\n",
        "    for i, method in enumerate(methods):\n",
        "        offset = i * bar_width - (len(methods) - 1) * bar_width / 2\n",
        "        axes[0].bar(index + offset, all_results[method]['avg_completion_times'], bar_width, label=method, color=colors.get(method))\n",
        "    axes[0].set_xlabel('Number of Vehicles')\n",
        "    axes[0].set_ylabel('Average Completion Time (s)')\n",
        "    axes[0].set_title('Completion Time vs Vehicles')\n",
        "    axes[0].set_xticks(index)\n",
        "    axes[0].set_xticklabels(num_vehicles)\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # Energy Consumption\n",
        "    for i, method in enumerate(methods):\n",
        "        offset = i * bar_width - (len(methods) - 1) * bar_width / 2\n",
        "        axes[1].bar(index + offset, all_results[method]['avg_total_energies'], bar_width, label=method, color=colors.get(method))\n",
        "    axes[1].set_xlabel('Number of Vehicles')\n",
        "    axes[1].set_ylabel('Total Energy (J)')\n",
        "    axes[1].set_title('Energy Consumption vs Vehicles')\n",
        "    axes[1].set_xticks(index)\n",
        "    axes[1].set_xticklabels(num_vehicles)\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"results_comparison_bar.png\", dpi=150)\n",
        "    plt.close(fig)\n",
        "    print(\"✅ Comparison chart saved as results_comparison_bar.png\")\n",
        "\n",
        "\n",
        "plot_results_comparison(all_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd38b45-1ff5-4e32-aae8-e704cbcb3e2d",
      "metadata": {
        "id": "1fd38b45-1ff5-4e32-aae8-e704cbcb3e2d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}